\documentclass[../main]{subfiles}

\begin{document}

\chapter{Results}
This chapter will discuss the results of the training, validation and testing.
In the first section the configurations with the best results will be shown with their average scores obtained during training and validation.
Subsequently, the results obtained from the best configurations will be shown in the testing section.
All f1-scores are accompanied by a defined interval thanks to the t-student, with an accuracy of 90\%.

\section{Validation}
The hyperparameters of the configurations with the best validation results are shown in Tables \ref{table:sklearn_model_best_conf} and \ref{table:torch_model_best_conf}.
In particular, the hyperparameters that led the models to achieve the best results are shown.
\begin{table}[!ht]
    \center
    \begin{tabular}{|l|l|}
        \hline
        \multicolumn{1}{|c|}{\textbf{Model}} & \multicolumn{1}{c|}{\textbf{Best configuration}}                                                    \\
        \hline
        \textit{RandomForestClassifier}    & \begin{tabular}[c]{@{}l@{}}n\_estimators: 700\\ max\_features: 'sqrt'\\ max\_depth: 10\end{tabular} \\
        \hline
        \textit{DecisionTreeClassifier}    & \begin{tabular}[c]{@{}l@{}}criterion: 'gini'\\ max\_depth: 10\end{tabular}                      \\
        \hline
        \textit{GaussianNB}                & var\_smoothing: 1.873817422860383e-06                                                              \\
        \hline
        \textit{SVM}                       & \begin{tabular}[c]{@{}l@{}}C: 100\\ gamma: 1e-2\\ kernel: 'rbf'\end{tabular}                       \\
        \hline
    \end{tabular}
    \caption{Best configurations for scikit-learn models.}
    \label{table:sklearn_model_best_conf}
\end{table}

\begin{table}[!ht]
    \center
    \begin{tabular}{|l|l|}
        \hline
        \multicolumn{1}{|c|}{\textbf{Model}} & \multicolumn{1}{c|}{\textbf{Best configuration}}                                                                                                                  \\
        \hline
        \textit{MovieNet (MLP)}     & \begin{tabular}[c]{@{}l@{}}n\_hidden\_layers: 3\\ dropout: 0.2\\ batch\_norm: False\\ batch\_size: 128\\ optim: optimizer.Adam\\ weight\_decay: 1e-7\end{tabular} \\
        \hline
    \end{tabular}
    \caption{Best configuration for PyTorch model.}
    \label{table:torch_model_best_conf}
\end{table}
\newpage

From the best configuration of MovieNet, some observations can be made:
\begin{itemize}
    \item In general, the best configurations have a number of hidden layers equal to the smallest value defined in the range.
    \item The value of weight decay was the smallest in the range, probably because the network was able to generalize the problem without overfitting.
\end{itemize}
The scikit-learn models will be commented on directly afterwards, so that the results can be compared.
The f1-score obtained by each model during the training and validation phase is shown in the Table \ref{table:train_val_results}.


\begin{table}[!ht]
    \center
    \begin{tabular}{|l|cc|}
        \hline
        \multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Model}}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{l|}{\textbf{Validation}} \\
        \cline{2-3} 
        \multicolumn{1}{|c|}{}                                & \multicolumn{2}{c|}{\textbf{f1-score (\%)}}                                       \\
        \hline
        \textit{RandomForestClassifier}                       & \multicolumn{1}{c|}{96.2 $\pm$0.1}         & 75.3 $\pm$0.1                               \\
        \hline
        \textit{DecisionTreeClassifier}                       & \multicolumn{1}{c|}{79.6 $\pm$0.6}        & 66.4 $\pm$0.1                                \\
        \hline
        \textit{GaussianNB}                                   & \multicolumn{1}{c|}{51.1 $\pm$0.2}         & 45.3 $\pm$0.2                                \\
        \hline
        \textit{SVM}                                          & \multicolumn{1}{c|}{97.6 $\pm$0.09}       & 82.8 $\pm$0.1                               \\
        \hline
        \textit{MovieNet (MLP)}                               & \multicolumn{1}{c|}{87.5 $\pm$0.1}         & 79.5 $\pm$0.08                               \\
        \hline
    \end{tabular}
    \caption{Training and validation results of each model with the best configurations.}
    \label{table:train_val_results}
\end{table}

\begin{figure}[!ht]
    \center
    \includegraphics[width=0.8\linewidth]{figures/train_val_plot.png}
    \caption{Multiple bar plot that shows the train/val f1-score for each model.}
    \label{fig:train_val_plot}
\end{figure}
\newpage

It can be seen that GaussianNB had more difficulties than the other models.
In particular, low results were obtained in both the training and validation phases, which is probably due to the non-independence of the data.
The other models, on the other hand, performed in line with expectations, with a validation value slightly lower than the train value.

\section{Testing}
The test phase is necessary to evaluate the performance of the model using samples that have never been taken.
It can be seen in Table \ref{table:test_results} how SVM and MovieNet achieved the highest metrics with the lowest losses.
Instead, GaussianNB, as we expected from the validation results, is the model with the worst metrics.

\begin{table}[!ht]
    \center
    \begin{tabular}{|l|cc|}
        \hline
        \multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Model}}} & \multicolumn{2}{c|}{\textbf{Testing}}               \\
        \cline{2-3} 
        \multicolumn{1}{|c|}{}                                & \multicolumn{1}{c|}{\textbf{f1-score (\%)}} & \textbf{loss}  \\ 
        \hline
        \textit{RandomForestClassifier}                       & \multicolumn{1}{c|}{75.8 $\pm$0.4}             & 0.241 \\
        \hline
        \textit{DecisionTreeClassifier}                       & \multicolumn{1}{c|}{66.9 $\pm$0.6}                & 0.331  \\
        \hline
        \textit{GaussianNB}                                   & \multicolumn{1}{c|}{45 $\pm$1.3}                & 0.549 \\
        \hline
        \textit{SVM}                                          & \multicolumn{1}{c|}{82.8 $\pm$0.3}              & 0.171  \\
        \hline
        \textit{MovieNet (MLP)}                                     & \multicolumn{1}{c|}{85.9 $\pm$0.3}              & 0.36  \\ \hline
    \end{tabular}
    \caption{Testing results of each model with the best configurations.}
    \label{table:test_results}
\end{table}

\begin{figure}[!ht]
    \center
    \includegraphics[width=0.8\linewidth]{figures/test_metric_plot.png}
    \caption{Multiplebar plot that shows the test f1-score for each model.}
    \label{fig:test_metric_plot}
\end{figure}

\end{document}