\documentclass[../main]{subfiles}

\begin{document}

\chapter{Methodology}
In the next chapter there will be the explaination of the data pipeline that the project followed.
In particular, each subsection will focus on a specific task, except for the data visualization that has been used only when needed.

\section{Data Acquisition}
The used datasets are downloaded at runtime directly from the sources.
These datasets come directly from MovieLens' page, which provides 6 different datasets:
% TODO: think about, link README.txt

    \begin{table}[h]
        \begin{tabular}{|l | l|}
        \hline
        \textbf{Dataset} & \textbf{Features} \\
        \hline
        ratings.csv &  userId, movieId, rating, timestamp\\
        \hline
        tags.csv &  userId, movieId, tag, timestamp\\
        \hline
        movies.csv &  movieId, title, genres\\
        \hline
        links.csv &  movieId, imdbId, tmdbId\\
        \hline
        genome-scores.csv &  movieId, tagId, relevance\\
        \hline
        genome-tags.csv & tagId, tag\\
        \hline
        \end{tabular}
    \end{table}
        


where most of these datasets provides information for approximately 60000 films.
The links dataset provides two identifiers that allow to collect information from the IMDB and TMDB databases.
Thanks to the links' features, it has been possible to collect some more information on the running times of the films that could provide more insight into them.
Talking about the ground truth of the supervisioned models, the rating mean is missing. So the target feature will be computed during the pre-process phase thanks to the ratings dataset.
Further information about the features usage and the cardinality of the datasets will be discussed in the Pre-Process section.


\section{Data Pre-process}
\section{Modeling}
\section{Performance Analysis}

\end{document}