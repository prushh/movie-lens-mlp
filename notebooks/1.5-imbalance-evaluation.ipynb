{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imbalance evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",

    "from sklearn import ensemble\n",

    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",

    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours, RandomUnderSampler\n",
    "from sklearn import tree, svm\n",

    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",

    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate, GridSearchCV, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",

    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from src.utils.const import DATA_DIR, SEED\n",
    "from src.utils.util_models import fix_random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Useful path to data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join(os.getcwd(), '..')\n",
    "PROCESSED_DIR = os.path.join(ROOT_DIR, DATA_DIR, 'processed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fix random seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "fix_random(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start to work"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "final = pd.read_parquet(os.path.join(PROCESSED_DIR, 'final.parquet'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add rating_discrete feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13147 entries, 0 to 13146\n",
      "Columns: 1153 entries, year to rating_discrete\n",
      "dtypes: float32(1130), float64(1), int32(22)\n",
      "memory usage: 58.0 MB\n"
     ]
    }
   ],
   "source": [
    "final = (final\n",
    "         .assign(rating_discrete=pd.cut(final.loc[:, 'rating_mean'], bins=N_BINS, labels=False))\n",
    "         .astype({'rating_discrete': 'int32'})\n",
    "         .drop(columns=['rating_mean']))\n",
    "final.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Separate train/test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "data = final.loc[:, final.columns != 'rating_discrete']\n",
    "target = final['rating_discrete']\n",
    "train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.2,\n",
    "                                                                    stratify=final['rating_discrete'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "models ={'random_forest' : ensemble.RandomForestClassifier(),\n",
    "        'decision_tree' :tree.DecisionTreeClassifier(),\n",
    "        'GaussianNB' : GaussianNB(),\n",
    "        'quadratic_discriminant' : QuadraticDiscriminantAnalysis(store_covariance=True),\n",
    "        'svm': svm.SVC()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def try_sample(train_data_inside, train_target_inside) -> None:\n",
    "    # Define evaluation procedure (here we use Repeated Stratified K-Fold CV)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1)\n",
    "    # Evaluate model\n",
    "    scoring = ['accuracy', 'precision_macro', 'recall_macro',]\n",
    "    results=[]\n",
    "    for elm in models.items():\n",
    "        scores = cross_validate(elm[1], train_data_inside, train_target_inside, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "        # summarize performance\n",
    "        elemento = {'model_name':elm[0],'mean_acc': np.mean(scores['test_accuracy']),'mean_prec': np.mean(scores['test_precision_macro']),'mean_recall': np.mean(scores['test_recall_macro'])}\n",
    "        results.append(elemento)\n",
    "    for elm in results:\n",
    "        print(f'{elm}\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "features = [\n",
    "    'year',\n",
    "    'title_length',\n",
    "    'runtime',\n",
    "    'rating_count',\n",
    "    'tag_count'\n",
    "]\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers=[\n",
    "        ('minmax', MinMaxScaler(), features)\n",
    "    ])\n",
    "\n",
    "norm = Normalizer(norm='l2')\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', scaler)\n",
    "    #,('norm', norm) #To review after checks\n",
    "])\n",
    "\n",
    "pipe.fit(train_data)\n",
    "train_data_proc = pipe.transform(train_data)\n",
    "test_data_proc = pipe.transform(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class weight balancing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### class_weights = 'balanced'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_balanced = RandomForestClassifier(criterion='entropy', class_weight='balanced')\n",
    "try_sample(model_balanced, train_data_proc, train_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### class_weights = 'balanced_subsample'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_balanced_subsample = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample')\n",
    "try_sample(model_balanced_subsample, train_data, train_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### class_weights = dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_weight = compute_class_weight('balanced', classes=np.unique(target), y=target)\n",
    "class_weight_dict = dict(enumerate(class_weight))\n",
    "\n",
    "model_dict = RandomForestClassifier(criterion='entropy', class_weight=class_weight_dict)\n",
    "try_sample(model_dict, train_data, train_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### balancer MLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def balancer(train_target_tmp: np.ndarray) -> utils.data.WeightedRandomSampler:\n",
    "    counts = np.bincount(train_target_tmp)\n",
    "    if counts.any(0):\n",
    "        np.seterr(divide='ignore')\n",
    "        labels_weights = 1. / counts\n",
    "        labels_weights[np.isinf(labels_weights)] = 0\n",
    "    else:\n",
    "        np.seterr(divide=None)\n",
    "        labels_weights = 1. / counts\n",
    "    weights = torch.tensor(labels_weights[train_target_tmp], dtype=torch.float)\n",
    "    return utils.data.WeightedRandomSampler(weights, len(weights), replacement=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ImbalancedLearn Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SMOTE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'random_forest', 'mean_acc': 0.929472049689441, 'mean_prec': 0.9291139192950977, 'mean_recall': 0.9294720496894411}\n",
      "\n",
      "\n",
      "{'model_name': 'decision_tree', 'mean_acc': 0.8504037267080746, 'mean_prec': 0.849383191268096, 'mean_recall': 0.8504037267080745}\n",
      "\n",
      "\n",
      "{'model_name': 'GaussianNB', 'mean_acc': 0.7059316770186336, 'mean_prec': 0.6932556396701524, 'mean_recall': 0.7059316770186335}\n",
      "\n",
      "\n",
      "{'model_name': 'quadratic_discriminant', 'mean_acc': 0.8106521739130435, 'mean_prec': 0.8824123760581525, 'mean_recall': 0.8106521739130435}\n",
      "\n",
      "\n",
      "{'model_name': 'svm', 'mean_acc': 0.9350621118012422, 'mean_prec': 0.9345567817585538, 'mean_recall': 0.9350621118012422}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTE(k_neighbors=4)\n",
    "train_data_smt_proc, train_target_smt_proc = smt.fit_resample(train_data_proc, train_target)\n",
    "try_sample(train_data_smt_proc, train_target_smt_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SMOTETomek"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'random_forest', 'mean_acc': 0.9231055900621119, 'mean_prec': 0.9226595657841709, 'mean_recall': 0.9231055900621118}\n",
      "\n",
      "\n",
      "{'model_name': 'decision_tree', 'mean_acc': 0.8436335403726708, 'mean_prec': 0.8419859963589995, 'mean_recall': 0.8436335403726707}\n",
      "\n",
      "\n",
      "{'model_name': 'GaussianNB', 'mean_acc': 0.4427329192546584, 'mean_prec': 0.44526048335660484, 'mean_recall': 0.4427329192546584}\n",
      "\n",
      "\n",
      "{'model_name': 'quadratic_discriminant', 'mean_acc': 0.7087577639751552, 'mean_prec': 0.86666902976784, 'mean_recall': 0.7087577639751552}\n",
      "\n",
      "\n",
      "{'model_name': 'svm', 'mean_acc': 0.2043167701863354, 'mean_prec': 0.13257023267521867, 'mean_recall': 0.20431677018633543}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smt_tom = SMOTETomek(smote=SMOTE(k_neighbors=4), tomek=TomekLinks(sampling_strategy='majority'))\n",
    "train_data_smt_tom, train_target_smt_tom = smt_tom.fit_resample(train_data, train_target)\n",
    "try_sample(train_data_smt_tom, train_target_smt_tom)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SMOTEENN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'random_forest', 'mean_acc': 0.9798646362098139, 'mean_prec': 0.9713143688225052, 'mean_recall': 0.8325466781342898}\n",
      "\n",
      "\n",
      "{'model_name': 'decision_tree', 'mean_acc': 0.9362098138747885, 'mean_prec': 0.8262500781483462, 'mean_recall': 0.8241686004483887}\n",
      "\n",
      "\n",
      "{'model_name': 'GaussianNB', 'mean_acc': 0.8315566835871404, 'mean_prec': 0.7137148685105816, 'mean_recall': 0.7390268698368387}\n",
      "\n",
      "\n",
      "{'model_name': 'quadratic_discriminant', 'mean_acc': 0.8939932318104906, 'mean_prec': 0.8332115122554947, 'mean_recall': 0.812517521334533}\n",
      "\n",
      "\n",
      "{'model_name': 'svm', 'mean_acc': 0.9818950930626058, 'mean_prec': 0.9702927664318479, 'mean_recall': 0.8700267609428209}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smt_enn = SMOTEENN(smote=SMOTE(k_neighbors=4), enn=EditedNearestNeighbours(n_neighbors=4))\n",
    "train_data_smt_enn_proc, train_target_smt_enn_proc = smt_enn.fit_resample(train_data_proc, train_target)\n",
    "try_sample(train_data_smt_enn_proc, train_target_smt_enn_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RandomOverSampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'random_forest', 'mean_acc': 0.9304347826086956, 'mean_prec': 0.9301174654319397, 'mean_recall': 0.9304347826086956}\n",
      "\n",
      "\n",
      "{'model_name': 'decision_tree', 'mean_acc': 0.8923291925465839, 'mean_prec': 0.8900562132272851, 'mean_recall': 0.8923291925465837}\n",
      "\n",
      "\n",
      "{'model_name': 'GaussianNB', 'mean_acc': 0.6799378881987577, 'mean_prec': 0.6670656265046275, 'mean_recall': 0.6799378881987577}\n",
      "\n",
      "\n",
      "{'model_name': 'quadratic_discriminant', 'mean_acc': 0.5304658385093168, 'mean_prec': 0.743573680288558, 'mean_recall': 0.5304658385093168}\n",
      "\n",
      "\n",
      "{'model_name': 'svm', 'mean_acc': 0.9257453416149068, 'mean_prec': 0.925051327542471, 'mean_recall': 0.9257453416149068}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd_over = RandomOverSampler()\n",
    "train_data_rnd_over_proc, train_target_rnd_over_proc = rnd_over.fit_resample(train_data_proc, train_target)\n",
    "try_sample(train_data_rnd_over_proc, train_target_rnd_over_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BaggingClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Min Threshold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "bins_count = train_target.value_counts()\n",
    "for i in range(len(bins_count)):\n",
    "    if bins_count[i] <= 500:\n",
    "        bins_count[i] = 500\n",
    "\n",
    "bin_sizes = bins_count.to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### RandomForestClassifier SMOTE with threshold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'random_forest', 'mean_acc': 0.7828694817658349, 'mean_prec': 0.8650451742963301, 'mean_recall': 0.818016533614155}\n",
      "\n",
      "\n",
      "{'model_name': 'decision_tree', 'mean_acc': 0.6624280230326296, 'mean_prec': 0.7226934054213032, 'mean_recall': 0.7241802768104111}\n",
      "\n",
      "\n",
      "{'model_name': 'GaussianNB', 'mean_acc': 0.5228726807421625, 'mean_prec': 0.6017537753876085, 'mean_recall': 0.6591913106246556}\n",
      "\n",
      "\n",
      "{'model_name': 'quadratic_discriminant', 'mean_acc': 0.4526551503518874, 'mean_prec': 0.5585288466013207, 'mean_recall': 0.5297962597672432}\n",
      "\n",
      "\n",
      "{'model_name': 'svm', 'mean_acc': 0.8106206014075495, 'mean_prec': 0.8570399215210651, 'mean_recall': 0.8333812165283485}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smt_new = SMOTE(k_neighbors=4, sampling_strategy=bin_sizes)\n",
    "train_data_smt_new, train_target_smt_new = smt_new.fit_resample(train_data_proc, train_target)\n",
    "try_sample(train_data_smt_new, train_target_smt_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2b585906",
   "language": "python",
   "display_name": "PyCharm (movie-lens-mlp)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}