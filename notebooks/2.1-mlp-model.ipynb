{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn\n",
    "from torch import utils\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchinfo import summary\n",
    "\n",
    "from src.data.dataset import MovieDataset\n",
    "from src.models.config import best_param_layers, best_param_grid_mlp\n",
    "from src.models.network.mlp import execute\n",
    "from src.models.network.validate import validate\n",
    "from src.utils.const import DATA_DIR, SEED\n",
    "from src.utils.util_models import fix_random, balancer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Useful path to data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join(os.getcwd(), '..')\n",
    "PROCESSED_DIR = os.path.join(ROOT_DIR, DATA_DIR, 'processed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fix random seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fix_random(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print('Using device:', torch.cuda.get_device_name(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import final dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_stored = pd.read_parquet(os.path.join(PROCESSED_DIR, 'final.parquet'))\n",
    "final = MovieDataset(final_stored)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MovieNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int,\n",
    "            input_act: nn.Module,\n",
    "            hidden_size: int,\n",
    "            hidden_act: nn.Module,\n",
    "            num_hidden_layers: int,\n",
    "            output_fn,\n",
    "            num_classes: int,\n",
    "            dropout: float = 0.0,\n",
    "            batch_norm: bool = False\n",
    "    ) -> None:\n",
    "        super(MovieNet, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            input_act\n",
    "        ])\n",
    "\n",
    "        for _ in range(num_hidden_layers):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "\n",
    "            if batch_norm:\n",
    "                self.layers.append(nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "            self.layers.append(hidden_act)\n",
    "\n",
    "            if dropout > 0.0:\n",
    "                self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        if output_fn:\n",
    "            self.layers.append(output_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def reset_weights(self):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mlp(dataset: MovieDataset):\n",
    "    features = [\n",
    "        dataset.idx_column['year'],\n",
    "        dataset.idx_column['title_length'],\n",
    "        dataset.idx_column['tag_count'],\n",
    "        dataset.idx_column['runtime'],\n",
    "        dataset.idx_column['rating_count']\n",
    "    ]\n",
    "\n",
    "    n_splits = 5\n",
    "    num_workers = 2\n",
    "    cv_outer = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv_outer.split(dataset.X, y=dataset.y), 1):\n",
    "        hyper_parameters_model_all = itertools.product(\n",
    "            best_param_layers['input_act'],\n",
    "            best_param_layers['hidden_act'],\n",
    "            best_param_layers['hidden_size'],\n",
    "            best_param_layers['num_hidden_layers'],\n",
    "            best_param_layers['dropout'],\n",
    "            best_param_layers['batch_norm'],\n",
    "            best_param_layers['output_fn'],\n",
    "            best_param_grid_mlp['starting_lr'],\n",
    "            best_param_grid_mlp['num_epochs'],\n",
    "            best_param_grid_mlp['batch_size'],\n",
    "            best_param_grid_mlp['optim'],\n",
    "            best_param_grid_mlp['momentum'],\n",
    "            best_param_grid_mlp['weight_decay'],\n",
    "        )\n",
    "\n",
    "        hyper_parameters_model = hyper_parameters_model_all\n",
    "\n",
    "        print('=' * 65)\n",
    "        print(f'Fold {fold}')\n",
    "\n",
    "        list_fold_stat = []\n",
    "        best_cfg_network = None\n",
    "        max_f1_test = 0\n",
    "        data_test = utils.data.Subset(dataset, test_idx)\n",
    "\n",
    "        loader_test = utils.data.DataLoader(data_test, batch_size=1,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "        for idx, (input_act,\n",
    "                  hidden_act,\n",
    "                  hidden_size,\n",
    "                  num_hidden_layers,\n",
    "                  dropout,\n",
    "                  batch_norm,\n",
    "                  _,\n",
    "                  starting_lr,\n",
    "                  num_epochs,\n",
    "                  batch_size,\n",
    "                  optimizer_class,\n",
    "                  momentum,\n",
    "                  weight_decay) in enumerate(hyper_parameters_model):\n",
    "\n",
    "            best_val_network = None\n",
    "            max_f1_val = 0\n",
    "\n",
    "            cfg = (\n",
    "                input_act, hidden_act, hidden_size, num_hidden_layers, dropout, batch_norm, starting_lr, num_epochs,\n",
    "                batch_size, optimizer_class, momentum, weight_decay)\n",
    "\n",
    "            cv_inner = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "            for inner_fold, (inner_train_idx, val_idx) in enumerate(\n",
    "                    cv_inner.split(dataset.X[train_idx], y=dataset.y[train_idx]), 1):\n",
    "\n",
    "                # Balancing\n",
    "                train_target = dataset.y[inner_train_idx]\n",
    "                sampler = balancer(train_target)\n",
    "\n",
    "                # Scaling\n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                dataset.scale(train_idx, test_idx, scaler, features)\n",
    "\n",
    "                data_train = utils.data.Subset(dataset, inner_train_idx)\n",
    "                data_val = utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "                loader_train = utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                                     sampler=sampler,\n",
    "                                                     pin_memory=True,\n",
    "                                                     num_workers=num_workers)\n",
    "\n",
    "                loader_val = utils.data.DataLoader(data_val, batch_size=1,\n",
    "                                                   shuffle=False,\n",
    "                                                   num_workers=num_workers)\n",
    "\n",
    "                input_size = dataset.X.shape[1]\n",
    "                num_classes = dataset.num_classes\n",
    "                network = MovieNet(input_size=input_size,\n",
    "                                   input_act=input_act,\n",
    "                                   hidden_size=hidden_size,\n",
    "                                   hidden_act=hidden_act,\n",
    "                                   num_hidden_layers=num_hidden_layers,\n",
    "                                   dropout=dropout,\n",
    "                                   output_fn=None,\n",
    "                                   num_classes=num_classes)\n",
    "                network.reset_weights()\n",
    "                network.to(device)\n",
    "\n",
    "                if fold == 1 and inner_fold == 1:\n",
    "                    print('=' * 65)\n",
    "                    print(f'Configuration [{idx}]: {cfg}')\n",
    "                    summary(network)\n",
    "\n",
    "                # TODO: fix experiment name\n",
    "                name_train = f'movie_net_experiment_{idx}'\n",
    "\n",
    "                if optimizer_class == torch.optim.Adam:\n",
    "                    optimizer = optimizer_class(network.parameters(),\n",
    "                                                lr=starting_lr,\n",
    "                                                weight_decay=weight_decay)\n",
    "                else:\n",
    "                    optimizer = optimizer_class(network.parameters(),\n",
    "                                                lr=starting_lr,\n",
    "                                                momentum=momentum,\n",
    "                                                weight_decay=weight_decay)\n",
    "\n",
    "                fold_stat = execute(name_train,\n",
    "                                    network,\n",
    "                                    optimizer,\n",
    "                                    num_epochs,\n",
    "                                    loader_train,\n",
    "                                    loader_val,\n",
    "                                    device)\n",
    "                list_fold_stat.append(fold_stat)\n",
    "\n",
    "                if fold_stat['f1_val'] >= max_f1_val:\n",
    "                    max_f1_val = fold_stat['f1_val']\n",
    "                    best_val_network = network\n",
    "\n",
    "            criterion = CrossEntropyLoss()\n",
    "            loss_test, acc_test, f1_test = validate(best_val_network, loader_test, device, criterion)\n",
    "\n",
    "            print(f'Test {fold}, loss={loss_test:3f}, accuracy={acc_test:3f}, f1={f1_test:3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp(final)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}