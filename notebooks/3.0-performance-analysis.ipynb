{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Read results datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook all the results obtained will be reported, with particular reference to the best configuration for each model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os.path\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.models.config import param_layers, param_grid_mlp, param_layers_batch, param_grid_mlp_batch\n",
    "from src.utils.const import MODEL_RESULTS_CSV, NETWORK_RESULT_CSV\n",
    "from typing import Tuple\n",
    "from src.visualization.visualize import barplot_multiple_columns\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Useful path to data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = os.path.join('..', MODEL_RESULTS_CSV)\n",
    "MLP_RESULTS_FOLDER = os.path.join('..', NETWORK_RESULT_CSV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read output csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "mlp_all = pd.read_csv(os.path.join(MLP_RESULTS_FOLDER, 'out_mlp_all.csv'))\n",
    "mlp_batch = pd.read_csv(os.path.join(MLP_RESULTS_FOLDER, 'out_mlp_batch.csv'))\n",
    "svm_res = pd.read_csv(os.path.join(RESULTS_FOLDER, 'out_svm.csv'))\n",
    "naive_res = pd.read_csv(os.path.join(RESULTS_FOLDER, 'best_out_naive_bayes.csv'))\n",
    "tree_res = pd.read_csv(os.path.join(RESULTS_FOLDER, 'best_out_tree_based.csv'))\n",
    "\n",
    "svm_val = pd.read_csv(os.path.join(RESULTS_FOLDER, 'out_grid_svm.csv'))\n",
    "naive_val = pd.read_csv(os.path.join(RESULTS_FOLDER, 'out_grid_naive_bayes.csv'))\n",
    "tree_val = pd.read_csv(os.path.join(RESULTS_FOLDER, 'out_grid_tree_based.csv'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find best configuration of MLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utility function to explore results DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to find configuration with the best f1-score for each fold."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def find_max_f1_cfg(df: pd.DataFrame) -> List:\n",
    "    cfg = []\n",
    "    for fold in df['fold'].unique():\n",
    "        idx = df[df['fold'] == fold]['f1_test'].idxmax()\n",
    "        cfg.append(df.iloc[idx]['cfg'])\n",
    "    cfgs = np.unique(np.array(cfg))\n",
    "    return cfgs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration ID: [ 3. 17. 18. 35.]\n"
     ]
    }
   ],
   "source": [
    "best_cfg = find_max_f1_cfg(mlp_all)\n",
    "print(f'Best configuration ID: {best_cfg}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having performed cross validation with several test sets, it is possible to obtain the mean value of the specified metric and its confidence interval, with 90% accuracy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "def mu_confidence_interval(data: np.ndarray) -> {}:\n",
    "    t = 2.13\n",
    "    mu = np.mean(data)\n",
    "    standard_deviation = np.std(data)\n",
    "    M = data.shape[0]\n",
    "    t_student = t * standard_deviation / np.sqrt(M)\n",
    "    first_interval = mu - t_student\n",
    "    second_interval = mu + t_student\n",
    "    return {\n",
    "        'mu': mu,\n",
    "        't_student': t_student,\n",
    "        'first_interval': first_interval,\n",
    "        'second_interval': second_interval\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to find the best configuration between the indexes that we found previously, this function calculate the mean on each configuration between the folds, and select the one which has the higher mean."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "def find_best_conf(lst_conf, df: pd.DataFrame) -> dict:\n",
    "    conf = []\n",
    "    for idx, cfg in enumerate(lst_conf):\n",
    "        conf.append(\n",
    "            {\n",
    "                'f1': mu_confidence_interval(df[df['cfg'] == cfg]['f1_test']),\n",
    "                'loss': mu_confidence_interval(df[df['cfg'] == cfg]['loss_test']),\n",
    "                'acc': mu_confidence_interval(df[df['cfg'] == cfg]['acc_test'])\n",
    "            }\n",
    "        )\n",
    "        conf[idx]['conf'] = cfg\n",
    "        conf[idx]['acc']['mu'] /= 100\n",
    "        conf[idx]['acc']['t_student'] /= 100\n",
    "    max = conf[0]\n",
    "\n",
    "    for elm in conf:\n",
    "        if max['f1']['mu'] < elm['f1']['mu']:\n",
    "            max = elm\n",
    "    return max"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since in the output files containing the results of the neural network, the configuration is stored via the index, it is necessary to recalculate all configurations and select only the one of interest, specifying the index."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def get_best_configuration_mlp(cfg: int, p_layer, p_grid_mlp) -> Tuple:\n",
    "    hyper_parameters_model_all = itertools.product(\n",
    "        p_layer['input_act'],\n",
    "        p_layer['hidden_act'],\n",
    "        p_layer['hidden_size'],\n",
    "        p_layer['num_hidden_layers'],\n",
    "        p_layer['dropout'],\n",
    "        p_layer['batch_norm'],\n",
    "        p_layer['output_fn'],\n",
    "        p_grid_mlp['num_epochs'],\n",
    "        p_grid_mlp['starting_lr'],\n",
    "        p_grid_mlp['batch_size'],\n",
    "        p_grid_mlp['optim'],\n",
    "        p_grid_mlp['momentum'],\n",
    "        p_grid_mlp['weight_decay'],\n",
    "    )\n",
    "    return list(hyper_parameters_model_all)[cfg]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility function to summary the calculated statistics and the relative configuration."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "df_test_metric = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "def summary_statistics_model(df_score: pd.DataFrame, dictionary: Dict, model: str, train: bool = False) -> pd.DataFrame:\n",
    "    if not train:\n",
    "        print(\n",
    "            f\"Best configuration {model} mean metrics:\\n\"\n",
    "            f\"f1_score: {dictionary['f1']['mu']} ±{dictionary['f1']['t_student']}\\n\"\n",
    "            f\"loss: {dictionary['loss']['mu']} ±{dictionary['loss']['t_student']}\\n\"\n",
    "            f\"acc: {dictionary['acc']['mu']} ±{dictionary['acc']['t_student']}\\n\\n\"\n",
    "            f\"Best hyperparams configuration:\"\n",
    "        )\n",
    "        if model == \"mlp\":\n",
    "            best_cfg_mlp_all = get_best_configuration_mlp(int(dictionary['conf']), param_layers, param_grid_mlp)\n",
    "            for idx, key in enumerate(param_layers.keys()):\n",
    "                print(f\"{key}: {best_cfg_mlp_all[idx]}\")\n",
    "            for idx, key in enumerate(param_grid_mlp.keys(), 7):\n",
    "                print(f\"{key}: {best_cfg_mlp_all[idx]}\")\n",
    "        else:\n",
    "            print(f\"{dictionary['conf']}\")\n",
    "\n",
    "        new_test_score = pd.DataFrame({\n",
    "            'model': [model],\n",
    "            'f1_mu': [dictionary['f1']['mu']],\n",
    "            'acc_mu': [dictionary['acc']['mu']],\n",
    "            'loss_mu': [dictionary['loss']['mu']],\n",
    "            'f1_ci': [dictionary['f1']['t_student']],\n",
    "            'acc_ci': [dictionary['acc']['t_student']],\n",
    "            'loss_ci': [dictionary['loss']['t_student']],\n",
    "        })\n",
    "        df_score = pd.concat([df_score, new_test_score], ignore_index=True)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Best configuration {model} mean metrics:\\n\"\n",
    "            f\"train f1: {dictionary['train_score']['mu']} ±{dictionary['train_score']['t_student']}\\n\"\n",
    "            f\"validation f1: {dictionary['val_score']['mu']} ±{dictionary['val_score']['t_student']}\\n\"\n",
    "        )\n",
    "        new_test_score = pd.DataFrame({\n",
    "            'model': [model],\n",
    "            'train_score': [dictionary['train_score']['mu']],\n",
    "            'val_score': [dictionary['val_score']['mu']],\n",
    "            'train_ci': [dictionary['train_score']['t_student']],\n",
    "            'val_ci': [dictionary['val_score']['t_student']]\n",
    "        })\n",
    "        df_score = pd.concat([df_score, new_test_score], ignore_index=True)\n",
    "    return df_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results best cfg mlp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration mlp mean metrics:\n",
      "f1_score: 0.8610175579840659 ±0.00978116142020269\n",
      "loss: 0.3575360378119963 ±0.016819444473308905\n",
      "acc: 0.8608039894305543 ±0.009829616674382115\n",
      "\n",
      "Best hyperparams configuration:\n",
      "input_act: LeakyReLU(negative_slope=0.01)\n",
      "hidden_act: LeakyReLU(negative_slope=0.01)\n",
      "hidden_size: 512\n",
      "num_hidden_layers: 3\n",
      "dropout: 0.2\n",
      "batch_norm: True\n",
      "output_fn: None\n",
      "num_epochs: 200\n",
      "starting_lr: 0.001\n",
      "batch_size: 128\n",
      "optim: <class 'torch.optim.adam.Adam'>\n",
      "momentum: 0.9\n",
      "weight_decay: 1e-05\n"
     ]
    }
   ],
   "source": [
    "res_mlp = find_best_conf(best_cfg, mlp_all)\n",
    "df_test_metric = summary_statistics_model(df_test_metric, res_mlp, \"mlp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### mlp with different batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0  cfg  fold  loss_test   acc_test   f1_test  mean_loss  \\\n0            0    0     1  18.940403  13.612167  0.148006   0.289398   \n1            1    1     1  13.517536  22.813688  0.216087   0.296447   \n2            2    2     1  18.105448  12.433460  0.142572   0.301010   \n3            3    3     1   0.751302  67.984791  0.684068   0.410880   \n4            4    4     1   1.168189  49.581749  0.505397   0.611775   \n5            5    5     1   2.254341  18.631179  0.154145   0.886728   \n6            6    6     1  12.516399  19.201521  0.186588   0.806154   \n7            7    7     1   9.610622  20.152091  0.193252   0.750074   \n8            8    8     1   8.661695  25.057034  0.219253   0.712597   \n9            9    9     1   2.770374  25.893536  0.240637   0.730237   \n10          10   10     1   2.178082  28.022814  0.224635   0.788966   \n11          11   11     1   2.289579  19.125475  0.148035   0.912474   \n12          12    0     2   5.828178  22.509506  0.191131   0.440478   \n13          13    1     2   5.978181  19.695817  0.150226   0.440467   \n14          14    2     2   3.269951  30.684411  0.281673   0.463411   \n15          15    3     2   0.945817  58.821293  0.588730   0.576282   \n16          16    4     2   1.097103  53.117871  0.538862   0.734099   \n17          17    5     2   2.280688  19.809886  0.171600   0.987963   \n18          18    6     2   4.381033  23.840304  0.177178   0.911900   \n19          19    7     2   5.283458  22.547529  0.157092   0.856075   \n20          20    8     2   3.831899  32.091255  0.258347   0.813936   \n21          21    9     2   3.871399  23.536122  0.176768   0.819556   \n22          22   10     2   1.055093  56.425856  0.571810   0.867215   \n23          23   11     2   2.296078  16.197719  0.164221   0.982693   \n24          24    0     3   0.498692  79.193610  0.791973   0.402095   \n25          25    1     3   7.262911  22.936478  0.176534   0.402557   \n26          26    2     3   0.579616  74.971472  0.750021   0.420268   \n27          27    3     3   0.780494  65.994675  0.662866   0.528486   \n28          28    4     3   2.030025  28.527957  0.255888   0.687300   \n29          29    5     3   2.291271  12.248003  0.107747   0.950278   \n30          30    6     3   5.458804  22.898440  0.178341   0.871154   \n31          31    7     3   3.692444  32.027387  0.277362   0.816153   \n32          32    8     3   4.457298  27.577025  0.209407   0.778215   \n33          33    9     3   2.464701  30.315709  0.264350   0.790917   \n34          34   10     3   1.924381  30.962343  0.267599   0.855967   \n35          35   11     3   2.296966  18.372005  0.117269   0.974238   \n36          36    0     4   7.403112  16.964625  0.119128   0.454879   \n37          37    1     4   4.995937  24.724230  0.219541   0.449225   \n38          38    2     4   0.658782  72.917459  0.728823   0.462066   \n39          39    3     4   3.914467  19.969570  0.155608   0.572289   \n40          40    4     4   1.882785  27.615063  0.224291   0.756923   \n41          41    5     4   2.257028  15.252948  0.135088   1.007771   \n42          42    6     4   7.386781  17.991632  0.150818   0.921627   \n43          43    7     4   6.499929  16.774439  0.146436   0.861984   \n44          44    8     4   0.564435  75.275770  0.752554   0.818962   \n45          45    9     4   4.230159  24.800304  0.194789   0.816713   \n46          46   10     4   2.133507  32.293648  0.255840   0.869075   \n47          47   11     4   2.289704  22.365919  0.122689   0.984491   \n48          48    0     5   7.434802  24.381894  0.176671   0.379040   \n49          49    1     5   0.514022  78.965386  0.789361   0.383768   \n50          50    2     5   7.100224  13.427159  0.097930   0.404577   \n51          51    3     5   3.982442  17.839483  0.140550   0.497902   \n52          52    4     5   3.074195  17.230886  0.109658   0.667668   \n53          53    5     5   2.298211   5.325219  0.038804   0.935022   \n54          54    6     5   4.851910  21.681248  0.157890   0.859018   \n55          55    7     5   6.053369  12.818562  0.105500   0.806396   \n56          56    8     5   7.487917  11.639407  0.079087   0.769866   \n57          57    9     5   2.688849  29.478889  0.252266   0.787365   \n58          58   10     5   1.193308  49.258273  0.504290   0.848962   \n59          59   11     5   2.291784  27.729175  0.160606   0.967607   \n\n    std_loss  mean_acc_val  std_acc_val  mean_acc_train  std_acc_train  \\\n0   0.013900     75.375842     0.475101       88.254775       0.562407   \n1   0.022876     75.671540     1.257495       87.909500       0.968884   \n2   0.020293     75.823471     1.143876       87.699934       0.865473   \n3   0.191540     72.575773     5.793029       83.027949       8.142960   \n4   0.437051     66.671148    12.934831       74.474675      18.603783   \n5   0.732925     57.278686    24.252981       65.782976      25.818213   \n6   0.706682     59.659431    23.200582       68.741819      24.977831   \n7   0.677493     61.345407    22.158502       70.762288      23.968632   \n8   0.647498     62.370921    21.092658       72.070202      22.899502   \n9   0.616622     61.641182    20.130258       71.050573      21.942100   \n10  0.616590     60.105156    19.802989       68.309591      22.646509   \n11  0.718543     56.219784    22.985344       64.405776      25.264968   \n12  0.017572     66.565125     0.532008       81.254468       0.825879   \n13  0.014978     66.798837     0.596181       81.240863       0.712141   \n14  0.036441     66.380344     1.100915       80.200721       1.653451   \n15  0.198349     63.183201     5.635736       75.401871       8.446124   \n16  0.362491     59.671546     8.654326       68.577224      15.622986   \n17  0.657070     50.940175    21.130167       60.606331      22.831350   \n18  0.636284     53.140174    20.292666       63.435018      22.248174   \n19  0.613310     54.892082    19.546129       65.507924      21.526086   \n20  0.590458     56.451260    18.963056       67.051285      20.762889   \n21  0.560516     56.974183    18.059832       66.650866      19.739054   \n22  0.555382     56.200553    17.400038       64.408098      20.115798   \n23  0.655311     52.369068    20.976534       60.876323      22.543751   \n24  0.020770     71.527192     0.844426       82.760444       0.924812   \n25  0.015134     71.453508     0.706731       82.724424       0.688173   \n26  0.028524     70.831526     1.255325       81.968118       1.241464   \n27  0.189604     68.102729     4.863261       77.220625       8.315313   \n28  0.360728     63.893221     9.516253       70.354955      15.642839   \n29  0.673963     55.585708    20.673400       62.361073      22.888275   \n30  0.653417     57.757004    19.867764       65.323740      22.401107   \n31  0.628325     59.153993    18.955033       67.345984      21.628257   \n32  0.602080     60.107457    18.077431       68.718008      20.760638   \n33  0.572708     59.624082    17.219157       67.984134      19.829306   \n34  0.583564     57.694033    17.522440       65.053532      21.057903   \n35  0.682670     53.926683    20.937119       61.466154      23.418681   \n36  0.023495     67.117157     2.180876       80.671241       1.000569   \n37  0.023501     67.725341     1.850006       80.889580       1.020508   \n38  0.027778     67.479633     1.639547       80.359702       1.166481   \n39  0.194547     64.378957     5.626853       75.627289       8.348169   \n40  0.409478     59.305896    11.341373       67.597410      17.773932   \n41  0.674059     50.742770    21.892341       59.901167      23.655655   \n42  0.658823     53.315866    21.228828       63.148800      23.304230   \n43  0.636203     55.231389    20.495852       65.346234      22.563879   \n44  0.612088     56.703336    19.776725       66.907616      21.730683   \n45  0.580806     57.408929    18.887688       66.807388      20.621745   \n46  0.578446     56.383943    18.330126       64.336658      21.176163   \n47  0.673236     52.656545    21.565106       60.811820      23.408145   \n48  0.012830     72.055484     0.784554       83.932587       0.649882   \n49  0.013711     72.149370     0.810250       83.764348       0.655411   \n50  0.033809     72.014375     0.990010       82.838593       1.522677   \n51  0.164971     70.135079     3.399416       78.781306       7.195614   \n52  0.370346     65.889755     9.035906       71.387758      16.131524   \n53  0.686798     57.961551    20.015809       62.994077      23.858967   \n54  0.662606     59.723316    19.031802       65.827806      23.156954   \n55  0.635335     61.026003    18.140484       67.747236      22.253673   \n56  0.607868     61.886208    17.275525       69.050499      21.303726   \n57  0.579229     61.261665    16.501380       68.035006      20.456959   \n58  0.585684     59.482351    16.710802       65.248626      21.403909   \n59  0.685043     55.896389    19.993290       61.596576      23.805249   \n\n    mean_f1_train  std_f1_train  mean_f1_val  std_f1_val  \n0        0.881785      0.005654     0.754430    0.003962  \n1        0.878310      0.009760     0.757455    0.012299  \n2        0.876271      0.008692     0.758931    0.011460  \n3        0.828278      0.083659     0.727154    0.056903  \n4        0.739389      0.193005     0.669061    0.127240  \n5        0.640302      0.283215     0.570275    0.250451  \n6        0.672284      0.273661     0.594345    0.239270  \n7        0.694280      0.262520     0.611319    0.228306  \n8        0.708747      0.250875     0.621693    0.217251  \n9        0.699167      0.239762     0.614613    0.207203  \n10       0.671101      0.245237     0.599881    0.203026  \n11       0.627610      0.275711     0.557799    0.239801  \n12       0.811308      0.008362     0.664787    0.005823  \n13       0.811321      0.007279     0.666611    0.007171  \n14       0.800896      0.016670     0.662219    0.011439  \n15       0.751580      0.086754     0.630598    0.055812  \n16       0.679587      0.163761     0.595991    0.085422  \n17       0.586325      0.256690     0.504586    0.219380  \n18       0.617256      0.249467     0.527081    0.210461  \n19       0.639975      0.241013     0.545022    0.202570  \n20       0.657006      0.232313     0.560969    0.196379  \n21       0.653655      0.220674     0.566869    0.187156  \n22       0.630522      0.222801     0.559650    0.179962  \n23       0.588664      0.254583     0.519160    0.218694  \n24       0.826631      0.009277     0.714694    0.008890  \n25       0.826210      0.006931     0.713868    0.007480  \n26       0.818665      0.012422     0.707843    0.012323  \n27       0.770146      0.084950     0.680688    0.048409  \n28       0.697595      0.164113     0.638587    0.095062  \n29       0.604692      0.256348     0.546041    0.225549  \n30       0.636881      0.250110     0.569011    0.216289  \n31       0.659031      0.241200     0.583903    0.206184  \n32       0.674229      0.231463     0.594184    0.196587  \n33       0.667585      0.220603     0.590174    0.186964  \n34       0.637320      0.231119     0.571981    0.187379  \n35       0.596121      0.260191     0.531046    0.225240  \n36       0.805536      0.010144     0.668982    0.021197  \n37       0.807827      0.010274     0.675478    0.018249  \n38       0.802527      0.011716     0.673000    0.016211  \n39       0.753948      0.085678     0.642936    0.054567  \n40       0.669750      0.185568     0.593853    0.109781  \n41       0.578482      0.265252     0.502270    0.228655  \n42       0.613764      0.260370     0.528564    0.221316  \n43       0.637829      0.251763     0.548161    0.213433  \n44       0.655054      0.242347     0.563376    0.205875  \n45       0.654885      0.229950     0.571124    0.196760  \n46       0.629266      0.233965     0.561356    0.190386  \n47       0.588282      0.262187     0.522276    0.224432  \n48       0.838400      0.006527     0.720647    0.007492  \n49       0.836791      0.006557     0.721526    0.008012  \n50       0.827552      0.015227     0.720188    0.009959  \n51       0.786153      0.073349     0.701487    0.033779  \n52       0.708343      0.168921     0.659317    0.089739  \n53       0.612546      0.264160     0.570088    0.217341  \n54       0.643240      0.255887     0.588873    0.206459  \n55       0.664217      0.245756     0.602901    0.196729  \n56       0.678644      0.235279     0.612221    0.187346  \n57       0.669173      0.225175     0.606719    0.178565  \n58       0.640269      0.233360     0.590158    0.178144  \n59       0.598251      0.263349     0.550737    0.215149  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>cfg</th>\n      <th>fold</th>\n      <th>loss_test</th>\n      <th>acc_test</th>\n      <th>f1_test</th>\n      <th>mean_loss</th>\n      <th>std_loss</th>\n      <th>mean_acc_val</th>\n      <th>std_acc_val</th>\n      <th>mean_acc_train</th>\n      <th>std_acc_train</th>\n      <th>mean_f1_train</th>\n      <th>std_f1_train</th>\n      <th>mean_f1_val</th>\n      <th>std_f1_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>18.940403</td>\n      <td>13.612167</td>\n      <td>0.148006</td>\n      <td>0.289398</td>\n      <td>0.013900</td>\n      <td>75.375842</td>\n      <td>0.475101</td>\n      <td>88.254775</td>\n      <td>0.562407</td>\n      <td>0.881785</td>\n      <td>0.005654</td>\n      <td>0.754430</td>\n      <td>0.003962</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13.517536</td>\n      <td>22.813688</td>\n      <td>0.216087</td>\n      <td>0.296447</td>\n      <td>0.022876</td>\n      <td>75.671540</td>\n      <td>1.257495</td>\n      <td>87.909500</td>\n      <td>0.968884</td>\n      <td>0.878310</td>\n      <td>0.009760</td>\n      <td>0.757455</td>\n      <td>0.012299</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>18.105448</td>\n      <td>12.433460</td>\n      <td>0.142572</td>\n      <td>0.301010</td>\n      <td>0.020293</td>\n      <td>75.823471</td>\n      <td>1.143876</td>\n      <td>87.699934</td>\n      <td>0.865473</td>\n      <td>0.876271</td>\n      <td>0.008692</td>\n      <td>0.758931</td>\n      <td>0.011460</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.751302</td>\n      <td>67.984791</td>\n      <td>0.684068</td>\n      <td>0.410880</td>\n      <td>0.191540</td>\n      <td>72.575773</td>\n      <td>5.793029</td>\n      <td>83.027949</td>\n      <td>8.142960</td>\n      <td>0.828278</td>\n      <td>0.083659</td>\n      <td>0.727154</td>\n      <td>0.056903</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1.168189</td>\n      <td>49.581749</td>\n      <td>0.505397</td>\n      <td>0.611775</td>\n      <td>0.437051</td>\n      <td>66.671148</td>\n      <td>12.934831</td>\n      <td>74.474675</td>\n      <td>18.603783</td>\n      <td>0.739389</td>\n      <td>0.193005</td>\n      <td>0.669061</td>\n      <td>0.127240</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2.254341</td>\n      <td>18.631179</td>\n      <td>0.154145</td>\n      <td>0.886728</td>\n      <td>0.732925</td>\n      <td>57.278686</td>\n      <td>24.252981</td>\n      <td>65.782976</td>\n      <td>25.818213</td>\n      <td>0.640302</td>\n      <td>0.283215</td>\n      <td>0.570275</td>\n      <td>0.250451</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>6</td>\n      <td>1</td>\n      <td>12.516399</td>\n      <td>19.201521</td>\n      <td>0.186588</td>\n      <td>0.806154</td>\n      <td>0.706682</td>\n      <td>59.659431</td>\n      <td>23.200582</td>\n      <td>68.741819</td>\n      <td>24.977831</td>\n      <td>0.672284</td>\n      <td>0.273661</td>\n      <td>0.594345</td>\n      <td>0.239270</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>9.610622</td>\n      <td>20.152091</td>\n      <td>0.193252</td>\n      <td>0.750074</td>\n      <td>0.677493</td>\n      <td>61.345407</td>\n      <td>22.158502</td>\n      <td>70.762288</td>\n      <td>23.968632</td>\n      <td>0.694280</td>\n      <td>0.262520</td>\n      <td>0.611319</td>\n      <td>0.228306</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8.661695</td>\n      <td>25.057034</td>\n      <td>0.219253</td>\n      <td>0.712597</td>\n      <td>0.647498</td>\n      <td>62.370921</td>\n      <td>21.092658</td>\n      <td>72.070202</td>\n      <td>22.899502</td>\n      <td>0.708747</td>\n      <td>0.250875</td>\n      <td>0.621693</td>\n      <td>0.217251</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2.770374</td>\n      <td>25.893536</td>\n      <td>0.240637</td>\n      <td>0.730237</td>\n      <td>0.616622</td>\n      <td>61.641182</td>\n      <td>20.130258</td>\n      <td>71.050573</td>\n      <td>21.942100</td>\n      <td>0.699167</td>\n      <td>0.239762</td>\n      <td>0.614613</td>\n      <td>0.207203</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>10</td>\n      <td>1</td>\n      <td>2.178082</td>\n      <td>28.022814</td>\n      <td>0.224635</td>\n      <td>0.788966</td>\n      <td>0.616590</td>\n      <td>60.105156</td>\n      <td>19.802989</td>\n      <td>68.309591</td>\n      <td>22.646509</td>\n      <td>0.671101</td>\n      <td>0.245237</td>\n      <td>0.599881</td>\n      <td>0.203026</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>11</td>\n      <td>1</td>\n      <td>2.289579</td>\n      <td>19.125475</td>\n      <td>0.148035</td>\n      <td>0.912474</td>\n      <td>0.718543</td>\n      <td>56.219784</td>\n      <td>22.985344</td>\n      <td>64.405776</td>\n      <td>25.264968</td>\n      <td>0.627610</td>\n      <td>0.275711</td>\n      <td>0.557799</td>\n      <td>0.239801</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0</td>\n      <td>2</td>\n      <td>5.828178</td>\n      <td>22.509506</td>\n      <td>0.191131</td>\n      <td>0.440478</td>\n      <td>0.017572</td>\n      <td>66.565125</td>\n      <td>0.532008</td>\n      <td>81.254468</td>\n      <td>0.825879</td>\n      <td>0.811308</td>\n      <td>0.008362</td>\n      <td>0.664787</td>\n      <td>0.005823</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5.978181</td>\n      <td>19.695817</td>\n      <td>0.150226</td>\n      <td>0.440467</td>\n      <td>0.014978</td>\n      <td>66.798837</td>\n      <td>0.596181</td>\n      <td>81.240863</td>\n      <td>0.712141</td>\n      <td>0.811321</td>\n      <td>0.007279</td>\n      <td>0.666611</td>\n      <td>0.007171</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3.269951</td>\n      <td>30.684411</td>\n      <td>0.281673</td>\n      <td>0.463411</td>\n      <td>0.036441</td>\n      <td>66.380344</td>\n      <td>1.100915</td>\n      <td>80.200721</td>\n      <td>1.653451</td>\n      <td>0.800896</td>\n      <td>0.016670</td>\n      <td>0.662219</td>\n      <td>0.011439</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.945817</td>\n      <td>58.821293</td>\n      <td>0.588730</td>\n      <td>0.576282</td>\n      <td>0.198349</td>\n      <td>63.183201</td>\n      <td>5.635736</td>\n      <td>75.401871</td>\n      <td>8.446124</td>\n      <td>0.751580</td>\n      <td>0.086754</td>\n      <td>0.630598</td>\n      <td>0.055812</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1.097103</td>\n      <td>53.117871</td>\n      <td>0.538862</td>\n      <td>0.734099</td>\n      <td>0.362491</td>\n      <td>59.671546</td>\n      <td>8.654326</td>\n      <td>68.577224</td>\n      <td>15.622986</td>\n      <td>0.679587</td>\n      <td>0.163761</td>\n      <td>0.595991</td>\n      <td>0.085422</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2.280688</td>\n      <td>19.809886</td>\n      <td>0.171600</td>\n      <td>0.987963</td>\n      <td>0.657070</td>\n      <td>50.940175</td>\n      <td>21.130167</td>\n      <td>60.606331</td>\n      <td>22.831350</td>\n      <td>0.586325</td>\n      <td>0.256690</td>\n      <td>0.504586</td>\n      <td>0.219380</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>6</td>\n      <td>2</td>\n      <td>4.381033</td>\n      <td>23.840304</td>\n      <td>0.177178</td>\n      <td>0.911900</td>\n      <td>0.636284</td>\n      <td>53.140174</td>\n      <td>20.292666</td>\n      <td>63.435018</td>\n      <td>22.248174</td>\n      <td>0.617256</td>\n      <td>0.249467</td>\n      <td>0.527081</td>\n      <td>0.210461</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>7</td>\n      <td>2</td>\n      <td>5.283458</td>\n      <td>22.547529</td>\n      <td>0.157092</td>\n      <td>0.856075</td>\n      <td>0.613310</td>\n      <td>54.892082</td>\n      <td>19.546129</td>\n      <td>65.507924</td>\n      <td>21.526086</td>\n      <td>0.639975</td>\n      <td>0.241013</td>\n      <td>0.545022</td>\n      <td>0.202570</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3.831899</td>\n      <td>32.091255</td>\n      <td>0.258347</td>\n      <td>0.813936</td>\n      <td>0.590458</td>\n      <td>56.451260</td>\n      <td>18.963056</td>\n      <td>67.051285</td>\n      <td>20.762889</td>\n      <td>0.657006</td>\n      <td>0.232313</td>\n      <td>0.560969</td>\n      <td>0.196379</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>9</td>\n      <td>2</td>\n      <td>3.871399</td>\n      <td>23.536122</td>\n      <td>0.176768</td>\n      <td>0.819556</td>\n      <td>0.560516</td>\n      <td>56.974183</td>\n      <td>18.059832</td>\n      <td>66.650866</td>\n      <td>19.739054</td>\n      <td>0.653655</td>\n      <td>0.220674</td>\n      <td>0.566869</td>\n      <td>0.187156</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>10</td>\n      <td>2</td>\n      <td>1.055093</td>\n      <td>56.425856</td>\n      <td>0.571810</td>\n      <td>0.867215</td>\n      <td>0.555382</td>\n      <td>56.200553</td>\n      <td>17.400038</td>\n      <td>64.408098</td>\n      <td>20.115798</td>\n      <td>0.630522</td>\n      <td>0.222801</td>\n      <td>0.559650</td>\n      <td>0.179962</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>11</td>\n      <td>2</td>\n      <td>2.296078</td>\n      <td>16.197719</td>\n      <td>0.164221</td>\n      <td>0.982693</td>\n      <td>0.655311</td>\n      <td>52.369068</td>\n      <td>20.976534</td>\n      <td>60.876323</td>\n      <td>22.543751</td>\n      <td>0.588664</td>\n      <td>0.254583</td>\n      <td>0.519160</td>\n      <td>0.218694</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.498692</td>\n      <td>79.193610</td>\n      <td>0.791973</td>\n      <td>0.402095</td>\n      <td>0.020770</td>\n      <td>71.527192</td>\n      <td>0.844426</td>\n      <td>82.760444</td>\n      <td>0.924812</td>\n      <td>0.826631</td>\n      <td>0.009277</td>\n      <td>0.714694</td>\n      <td>0.008890</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7.262911</td>\n      <td>22.936478</td>\n      <td>0.176534</td>\n      <td>0.402557</td>\n      <td>0.015134</td>\n      <td>71.453508</td>\n      <td>0.706731</td>\n      <td>82.724424</td>\n      <td>0.688173</td>\n      <td>0.826210</td>\n      <td>0.006931</td>\n      <td>0.713868</td>\n      <td>0.007480</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0.579616</td>\n      <td>74.971472</td>\n      <td>0.750021</td>\n      <td>0.420268</td>\n      <td>0.028524</td>\n      <td>70.831526</td>\n      <td>1.255325</td>\n      <td>81.968118</td>\n      <td>1.241464</td>\n      <td>0.818665</td>\n      <td>0.012422</td>\n      <td>0.707843</td>\n      <td>0.012323</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.780494</td>\n      <td>65.994675</td>\n      <td>0.662866</td>\n      <td>0.528486</td>\n      <td>0.189604</td>\n      <td>68.102729</td>\n      <td>4.863261</td>\n      <td>77.220625</td>\n      <td>8.315313</td>\n      <td>0.770146</td>\n      <td>0.084950</td>\n      <td>0.680688</td>\n      <td>0.048409</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.030025</td>\n      <td>28.527957</td>\n      <td>0.255888</td>\n      <td>0.687300</td>\n      <td>0.360728</td>\n      <td>63.893221</td>\n      <td>9.516253</td>\n      <td>70.354955</td>\n      <td>15.642839</td>\n      <td>0.697595</td>\n      <td>0.164113</td>\n      <td>0.638587</td>\n      <td>0.095062</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2.291271</td>\n      <td>12.248003</td>\n      <td>0.107747</td>\n      <td>0.950278</td>\n      <td>0.673963</td>\n      <td>55.585708</td>\n      <td>20.673400</td>\n      <td>62.361073</td>\n      <td>22.888275</td>\n      <td>0.604692</td>\n      <td>0.256348</td>\n      <td>0.546041</td>\n      <td>0.225549</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>6</td>\n      <td>3</td>\n      <td>5.458804</td>\n      <td>22.898440</td>\n      <td>0.178341</td>\n      <td>0.871154</td>\n      <td>0.653417</td>\n      <td>57.757004</td>\n      <td>19.867764</td>\n      <td>65.323740</td>\n      <td>22.401107</td>\n      <td>0.636881</td>\n      <td>0.250110</td>\n      <td>0.569011</td>\n      <td>0.216289</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3.692444</td>\n      <td>32.027387</td>\n      <td>0.277362</td>\n      <td>0.816153</td>\n      <td>0.628325</td>\n      <td>59.153993</td>\n      <td>18.955033</td>\n      <td>67.345984</td>\n      <td>21.628257</td>\n      <td>0.659031</td>\n      <td>0.241200</td>\n      <td>0.583903</td>\n      <td>0.206184</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>8</td>\n      <td>3</td>\n      <td>4.457298</td>\n      <td>27.577025</td>\n      <td>0.209407</td>\n      <td>0.778215</td>\n      <td>0.602080</td>\n      <td>60.107457</td>\n      <td>18.077431</td>\n      <td>68.718008</td>\n      <td>20.760638</td>\n      <td>0.674229</td>\n      <td>0.231463</td>\n      <td>0.594184</td>\n      <td>0.196587</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>9</td>\n      <td>3</td>\n      <td>2.464701</td>\n      <td>30.315709</td>\n      <td>0.264350</td>\n      <td>0.790917</td>\n      <td>0.572708</td>\n      <td>59.624082</td>\n      <td>17.219157</td>\n      <td>67.984134</td>\n      <td>19.829306</td>\n      <td>0.667585</td>\n      <td>0.220603</td>\n      <td>0.590174</td>\n      <td>0.186964</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1.924381</td>\n      <td>30.962343</td>\n      <td>0.267599</td>\n      <td>0.855967</td>\n      <td>0.583564</td>\n      <td>57.694033</td>\n      <td>17.522440</td>\n      <td>65.053532</td>\n      <td>21.057903</td>\n      <td>0.637320</td>\n      <td>0.231119</td>\n      <td>0.571981</td>\n      <td>0.187379</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>11</td>\n      <td>3</td>\n      <td>2.296966</td>\n      <td>18.372005</td>\n      <td>0.117269</td>\n      <td>0.974238</td>\n      <td>0.682670</td>\n      <td>53.926683</td>\n      <td>20.937119</td>\n      <td>61.466154</td>\n      <td>23.418681</td>\n      <td>0.596121</td>\n      <td>0.260191</td>\n      <td>0.531046</td>\n      <td>0.225240</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>0</td>\n      <td>4</td>\n      <td>7.403112</td>\n      <td>16.964625</td>\n      <td>0.119128</td>\n      <td>0.454879</td>\n      <td>0.023495</td>\n      <td>67.117157</td>\n      <td>2.180876</td>\n      <td>80.671241</td>\n      <td>1.000569</td>\n      <td>0.805536</td>\n      <td>0.010144</td>\n      <td>0.668982</td>\n      <td>0.021197</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4.995937</td>\n      <td>24.724230</td>\n      <td>0.219541</td>\n      <td>0.449225</td>\n      <td>0.023501</td>\n      <td>67.725341</td>\n      <td>1.850006</td>\n      <td>80.889580</td>\n      <td>1.020508</td>\n      <td>0.807827</td>\n      <td>0.010274</td>\n      <td>0.675478</td>\n      <td>0.018249</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>38</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0.658782</td>\n      <td>72.917459</td>\n      <td>0.728823</td>\n      <td>0.462066</td>\n      <td>0.027778</td>\n      <td>67.479633</td>\n      <td>1.639547</td>\n      <td>80.359702</td>\n      <td>1.166481</td>\n      <td>0.802527</td>\n      <td>0.011716</td>\n      <td>0.673000</td>\n      <td>0.016211</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3.914467</td>\n      <td>19.969570</td>\n      <td>0.155608</td>\n      <td>0.572289</td>\n      <td>0.194547</td>\n      <td>64.378957</td>\n      <td>5.626853</td>\n      <td>75.627289</td>\n      <td>8.348169</td>\n      <td>0.753948</td>\n      <td>0.085678</td>\n      <td>0.642936</td>\n      <td>0.054567</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>40</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1.882785</td>\n      <td>27.615063</td>\n      <td>0.224291</td>\n      <td>0.756923</td>\n      <td>0.409478</td>\n      <td>59.305896</td>\n      <td>11.341373</td>\n      <td>67.597410</td>\n      <td>17.773932</td>\n      <td>0.669750</td>\n      <td>0.185568</td>\n      <td>0.593853</td>\n      <td>0.109781</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>41</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2.257028</td>\n      <td>15.252948</td>\n      <td>0.135088</td>\n      <td>1.007771</td>\n      <td>0.674059</td>\n      <td>50.742770</td>\n      <td>21.892341</td>\n      <td>59.901167</td>\n      <td>23.655655</td>\n      <td>0.578482</td>\n      <td>0.265252</td>\n      <td>0.502270</td>\n      <td>0.228655</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>42</td>\n      <td>6</td>\n      <td>4</td>\n      <td>7.386781</td>\n      <td>17.991632</td>\n      <td>0.150818</td>\n      <td>0.921627</td>\n      <td>0.658823</td>\n      <td>53.315866</td>\n      <td>21.228828</td>\n      <td>63.148800</td>\n      <td>23.304230</td>\n      <td>0.613764</td>\n      <td>0.260370</td>\n      <td>0.528564</td>\n      <td>0.221316</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>43</td>\n      <td>7</td>\n      <td>4</td>\n      <td>6.499929</td>\n      <td>16.774439</td>\n      <td>0.146436</td>\n      <td>0.861984</td>\n      <td>0.636203</td>\n      <td>55.231389</td>\n      <td>20.495852</td>\n      <td>65.346234</td>\n      <td>22.563879</td>\n      <td>0.637829</td>\n      <td>0.251763</td>\n      <td>0.548161</td>\n      <td>0.213433</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>44</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0.564435</td>\n      <td>75.275770</td>\n      <td>0.752554</td>\n      <td>0.818962</td>\n      <td>0.612088</td>\n      <td>56.703336</td>\n      <td>19.776725</td>\n      <td>66.907616</td>\n      <td>21.730683</td>\n      <td>0.655054</td>\n      <td>0.242347</td>\n      <td>0.563376</td>\n      <td>0.205875</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>45</td>\n      <td>9</td>\n      <td>4</td>\n      <td>4.230159</td>\n      <td>24.800304</td>\n      <td>0.194789</td>\n      <td>0.816713</td>\n      <td>0.580806</td>\n      <td>57.408929</td>\n      <td>18.887688</td>\n      <td>66.807388</td>\n      <td>20.621745</td>\n      <td>0.654885</td>\n      <td>0.229950</td>\n      <td>0.571124</td>\n      <td>0.196760</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>46</td>\n      <td>10</td>\n      <td>4</td>\n      <td>2.133507</td>\n      <td>32.293648</td>\n      <td>0.255840</td>\n      <td>0.869075</td>\n      <td>0.578446</td>\n      <td>56.383943</td>\n      <td>18.330126</td>\n      <td>64.336658</td>\n      <td>21.176163</td>\n      <td>0.629266</td>\n      <td>0.233965</td>\n      <td>0.561356</td>\n      <td>0.190386</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>11</td>\n      <td>4</td>\n      <td>2.289704</td>\n      <td>22.365919</td>\n      <td>0.122689</td>\n      <td>0.984491</td>\n      <td>0.673236</td>\n      <td>52.656545</td>\n      <td>21.565106</td>\n      <td>60.811820</td>\n      <td>23.408145</td>\n      <td>0.588282</td>\n      <td>0.262187</td>\n      <td>0.522276</td>\n      <td>0.224432</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>48</td>\n      <td>0</td>\n      <td>5</td>\n      <td>7.434802</td>\n      <td>24.381894</td>\n      <td>0.176671</td>\n      <td>0.379040</td>\n      <td>0.012830</td>\n      <td>72.055484</td>\n      <td>0.784554</td>\n      <td>83.932587</td>\n      <td>0.649882</td>\n      <td>0.838400</td>\n      <td>0.006527</td>\n      <td>0.720647</td>\n      <td>0.007492</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>49</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.514022</td>\n      <td>78.965386</td>\n      <td>0.789361</td>\n      <td>0.383768</td>\n      <td>0.013711</td>\n      <td>72.149370</td>\n      <td>0.810250</td>\n      <td>83.764348</td>\n      <td>0.655411</td>\n      <td>0.836791</td>\n      <td>0.006557</td>\n      <td>0.721526</td>\n      <td>0.008012</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>50</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7.100224</td>\n      <td>13.427159</td>\n      <td>0.097930</td>\n      <td>0.404577</td>\n      <td>0.033809</td>\n      <td>72.014375</td>\n      <td>0.990010</td>\n      <td>82.838593</td>\n      <td>1.522677</td>\n      <td>0.827552</td>\n      <td>0.015227</td>\n      <td>0.720188</td>\n      <td>0.009959</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>51</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3.982442</td>\n      <td>17.839483</td>\n      <td>0.140550</td>\n      <td>0.497902</td>\n      <td>0.164971</td>\n      <td>70.135079</td>\n      <td>3.399416</td>\n      <td>78.781306</td>\n      <td>7.195614</td>\n      <td>0.786153</td>\n      <td>0.073349</td>\n      <td>0.701487</td>\n      <td>0.033779</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>52</td>\n      <td>4</td>\n      <td>5</td>\n      <td>3.074195</td>\n      <td>17.230886</td>\n      <td>0.109658</td>\n      <td>0.667668</td>\n      <td>0.370346</td>\n      <td>65.889755</td>\n      <td>9.035906</td>\n      <td>71.387758</td>\n      <td>16.131524</td>\n      <td>0.708343</td>\n      <td>0.168921</td>\n      <td>0.659317</td>\n      <td>0.089739</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>53</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2.298211</td>\n      <td>5.325219</td>\n      <td>0.038804</td>\n      <td>0.935022</td>\n      <td>0.686798</td>\n      <td>57.961551</td>\n      <td>20.015809</td>\n      <td>62.994077</td>\n      <td>23.858967</td>\n      <td>0.612546</td>\n      <td>0.264160</td>\n      <td>0.570088</td>\n      <td>0.217341</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>54</td>\n      <td>6</td>\n      <td>5</td>\n      <td>4.851910</td>\n      <td>21.681248</td>\n      <td>0.157890</td>\n      <td>0.859018</td>\n      <td>0.662606</td>\n      <td>59.723316</td>\n      <td>19.031802</td>\n      <td>65.827806</td>\n      <td>23.156954</td>\n      <td>0.643240</td>\n      <td>0.255887</td>\n      <td>0.588873</td>\n      <td>0.206459</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>55</td>\n      <td>7</td>\n      <td>5</td>\n      <td>6.053369</td>\n      <td>12.818562</td>\n      <td>0.105500</td>\n      <td>0.806396</td>\n      <td>0.635335</td>\n      <td>61.026003</td>\n      <td>18.140484</td>\n      <td>67.747236</td>\n      <td>22.253673</td>\n      <td>0.664217</td>\n      <td>0.245756</td>\n      <td>0.602901</td>\n      <td>0.196729</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>56</td>\n      <td>8</td>\n      <td>5</td>\n      <td>7.487917</td>\n      <td>11.639407</td>\n      <td>0.079087</td>\n      <td>0.769866</td>\n      <td>0.607868</td>\n      <td>61.886208</td>\n      <td>17.275525</td>\n      <td>69.050499</td>\n      <td>21.303726</td>\n      <td>0.678644</td>\n      <td>0.235279</td>\n      <td>0.612221</td>\n      <td>0.187346</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>57</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2.688849</td>\n      <td>29.478889</td>\n      <td>0.252266</td>\n      <td>0.787365</td>\n      <td>0.579229</td>\n      <td>61.261665</td>\n      <td>16.501380</td>\n      <td>68.035006</td>\n      <td>20.456959</td>\n      <td>0.669173</td>\n      <td>0.225175</td>\n      <td>0.606719</td>\n      <td>0.178565</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>58</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1.193308</td>\n      <td>49.258273</td>\n      <td>0.504290</td>\n      <td>0.848962</td>\n      <td>0.585684</td>\n      <td>59.482351</td>\n      <td>16.710802</td>\n      <td>65.248626</td>\n      <td>21.403909</td>\n      <td>0.640269</td>\n      <td>0.233360</td>\n      <td>0.590158</td>\n      <td>0.178144</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>59</td>\n      <td>11</td>\n      <td>5</td>\n      <td>2.291784</td>\n      <td>27.729175</td>\n      <td>0.160606</td>\n      <td>0.967607</td>\n      <td>0.685043</td>\n      <td>55.896389</td>\n      <td>19.993290</td>\n      <td>61.596576</td>\n      <td>23.805249</td>\n      <td>0.598251</td>\n      <td>0.263349</td>\n      <td>0.550737</td>\n      <td>0.215149</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index  batch_norm  batch_size   f1_mean  f1_confidence  loss_mean  \\\n",
      "0       0        True          16  0.285382       0.242427   8.021037   \n",
      "1       1        True          32  0.310350       0.229459   6.453717   \n",
      "2       2        True          64  0.400204       0.270151   5.942804   \n",
      "3       3        True         512  0.446364       0.233992   2.074904   \n",
      "4       4        True        2048  0.326819       0.159141   1.850459   \n",
      "5       5        True       16384  0.121477       0.044247   2.276308   \n",
      "6       6       False          16  0.170163       0.012856   6.918986   \n",
      "7       7       False          32  0.175928       0.055172   6.227965   \n",
      "8       8       False          64  0.303729       0.221356   5.000649   \n",
      "9       9       False         512  0.225762       0.032366   3.205096   \n",
      "10     10       False        2048  0.364835       0.136903   1.696874   \n",
      "11     11       False       16384  0.142564       0.018369   2.292822   \n",
      "\n",
      "    loss_confidence   acc_mean  acc_confidence  \n",
      "0          5.736820  31.332360       23.087817  \n",
      "1          4.000400  33.827120       21.553753  \n",
      "2          6.218700  40.886792       26.451277  \n",
      "3          1.458697  46.121962       21.376658  \n",
      "4          0.682113  35.214705       13.149677  \n",
      "5          0.016917  14.253447        4.945503  \n",
      "6          2.838452  21.122629        2.101917  \n",
      "7          1.850419  20.864002        6.164735  \n",
      "8          2.725434  34.328098       20.554320  \n",
      "9          0.673349  26.804912        2.520606  \n",
      "10         0.454730  39.392587       10.761874  \n",
      "11         0.002985  20.758058        3.818276  \n"
     ]
    }
   ],
   "source": [
    "for idx in mlp_batch['cfg'].unique():\n",
    "    config = get_best_configuration_mlp(idx, param_layers_batch, param_grid_mlp_batch)\n",
    "    batch_norm = config[5]\n",
    "    batch_size = config[9]\n",
    "    f1_dict = mu_confidence_interval(mlp_batch[mlp_batch['cfg'] == idx]['f1_test'])\n",
    "    loss_dict = mu_confidence_interval(mlp_batch[mlp_batch['cfg'] == idx]['loss_test'])\n",
    "    acc_dict = mu_confidence_interval(mlp_batch[mlp_batch['cfg'] == idx]['acc_test'])\n",
    "\n",
    "    new_sample = pd.DataFrame({\n",
    "        'index': [idx],\n",
    "        'batch_norm': [batch_norm],\n",
    "        'batch_size': [batch_size],\n",
    "        'f1_mean': [f1_dict['mu']],\n",
    "        'f1_confidence': [f1_dict['t_student']],\n",
    "        'loss_mean': [loss_dict['mu']],\n",
    "        'loss_confidence': [loss_dict['t_student']],\n",
    "        'acc_mean': [acc_dict['mu']],\n",
    "        'acc_confidence': [acc_dict['t_student']]\n",
    "\n",
    "    })\n",
    "    df = pd.concat([df, new_sample], ignore_index=True)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "res_mlp = find_best_conf(best_cfg, mlp_all)\n",
    "# df_test_metric = summary_statistics_model(df_test_metric, res_mlp, \"mlp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### mlp with different batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0  cfg  fold  loss_test   acc_test   f1_test  mean_loss  \\\n0            0    0     1  18.940403  13.612167  0.148006   0.289398   \n1            1    1     1  13.517536  22.813688  0.216087   0.296447   \n2            2    2     1  18.105448  12.433460  0.142572   0.301010   \n3            3    3     1   0.751302  67.984791  0.684068   0.410880   \n4            4    4     1   1.168189  49.581749  0.505397   0.611775   \n5            5    5     1   2.254341  18.631179  0.154145   0.886728   \n6            6    6     1  12.516399  19.201521  0.186588   0.806154   \n7            7    7     1   9.610622  20.152091  0.193252   0.750074   \n8            8    8     1   8.661695  25.057034  0.219253   0.712597   \n9            9    9     1   2.770374  25.893536  0.240637   0.730237   \n10          10   10     1   2.178082  28.022814  0.224635   0.788966   \n11          11   11     1   2.289579  19.125475  0.148035   0.912474   \n12          12    0     2   5.828178  22.509506  0.191131   0.440478   \n13          13    1     2   5.978181  19.695817  0.150226   0.440467   \n14          14    2     2   3.269951  30.684411  0.281673   0.463411   \n15          15    3     2   0.945817  58.821293  0.588730   0.576282   \n16          16    4     2   1.097103  53.117871  0.538862   0.734099   \n17          17    5     2   2.280688  19.809886  0.171600   0.987963   \n18          18    6     2   4.381033  23.840304  0.177178   0.911900   \n19          19    7     2   5.283458  22.547529  0.157092   0.856075   \n20          20    8     2   3.831899  32.091255  0.258347   0.813936   \n21          21    9     2   3.871399  23.536122  0.176768   0.819556   \n22          22   10     2   1.055093  56.425856  0.571810   0.867215   \n23          23   11     2   2.296078  16.197719  0.164221   0.982693   \n24          24    0     3   0.498692  79.193610  0.791973   0.402095   \n25          25    1     3   7.262911  22.936478  0.176534   0.402557   \n26          26    2     3   0.579616  74.971472  0.750021   0.420268   \n27          27    3     3   0.780494  65.994675  0.662866   0.528486   \n28          28    4     3   2.030025  28.527957  0.255888   0.687300   \n29          29    5     3   2.291271  12.248003  0.107747   0.950278   \n30          30    6     3   5.458804  22.898440  0.178341   0.871154   \n31          31    7     3   3.692444  32.027387  0.277362   0.816153   \n32          32    8     3   4.457298  27.577025  0.209407   0.778215   \n33          33    9     3   2.464701  30.315709  0.264350   0.790917   \n34          34   10     3   1.924381  30.962343  0.267599   0.855967   \n35          35   11     3   2.296966  18.372005  0.117269   0.974238   \n36          36    0     4   7.403112  16.964625  0.119128   0.454879   \n37          37    1     4   4.995937  24.724230  0.219541   0.449225   \n38          38    2     4   0.658782  72.917459  0.728823   0.462066   \n39          39    3     4   3.914467  19.969570  0.155608   0.572289   \n40          40    4     4   1.882785  27.615063  0.224291   0.756923   \n41          41    5     4   2.257028  15.252948  0.135088   1.007771   \n42          42    6     4   7.386781  17.991632  0.150818   0.921627   \n43          43    7     4   6.499929  16.774439  0.146436   0.861984   \n44          44    8     4   0.564435  75.275770  0.752554   0.818962   \n45          45    9     4   4.230159  24.800304  0.194789   0.816713   \n46          46   10     4   2.133507  32.293648  0.255840   0.869075   \n47          47   11     4   2.289704  22.365919  0.122689   0.984491   \n48          48    0     5   7.434802  24.381894  0.176671   0.379040   \n49          49    1     5   0.514022  78.965386  0.789361   0.383768   \n50          50    2     5   7.100224  13.427159  0.097930   0.404577   \n51          51    3     5   3.982442  17.839483  0.140550   0.497902   \n52          52    4     5   3.074195  17.230886  0.109658   0.667668   \n53          53    5     5   2.298211   5.325219  0.038804   0.935022   \n54          54    6     5   4.851910  21.681248  0.157890   0.859018   \n55          55    7     5   6.053369  12.818562  0.105500   0.806396   \n56          56    8     5   7.487917  11.639407  0.079087   0.769866   \n57          57    9     5   2.688849  29.478889  0.252266   0.787365   \n58          58   10     5   1.193308  49.258273  0.504290   0.848962   \n59          59   11     5   2.291784  27.729175  0.160606   0.967607   \n\n    std_loss  mean_acc_val  std_acc_val  mean_acc_train  std_acc_train  \\\n0   0.013900     75.375842     0.475101       88.254775       0.562407   \n1   0.022876     75.671540     1.257495       87.909500       0.968884   \n2   0.020293     75.823471     1.143876       87.699934       0.865473   \n3   0.191540     72.575773     5.793029       83.027949       8.142960   \n4   0.437051     66.671148    12.934831       74.474675      18.603783   \n5   0.732925     57.278686    24.252981       65.782976      25.818213   \n6   0.706682     59.659431    23.200582       68.741819      24.977831   \n7   0.677493     61.345407    22.158502       70.762288      23.968632   \n8   0.647498     62.370921    21.092658       72.070202      22.899502   \n9   0.616622     61.641182    20.130258       71.050573      21.942100   \n10  0.616590     60.105156    19.802989       68.309591      22.646509   \n11  0.718543     56.219784    22.985344       64.405776      25.264968   \n12  0.017572     66.565125     0.532008       81.254468       0.825879   \n13  0.014978     66.798837     0.596181       81.240863       0.712141   \n14  0.036441     66.380344     1.100915       80.200721       1.653451   \n15  0.198349     63.183201     5.635736       75.401871       8.446124   \n16  0.362491     59.671546     8.654326       68.577224      15.622986   \n17  0.657070     50.940175    21.130167       60.606331      22.831350   \n18  0.636284     53.140174    20.292666       63.435018      22.248174   \n19  0.613310     54.892082    19.546129       65.507924      21.526086   \n20  0.590458     56.451260    18.963056       67.051285      20.762889   \n21  0.560516     56.974183    18.059832       66.650866      19.739054   \n22  0.555382     56.200553    17.400038       64.408098      20.115798   \n23  0.655311     52.369068    20.976534       60.876323      22.543751   \n24  0.020770     71.527192     0.844426       82.760444       0.924812   \n25  0.015134     71.453508     0.706731       82.724424       0.688173   \n26  0.028524     70.831526     1.255325       81.968118       1.241464   \n27  0.189604     68.102729     4.863261       77.220625       8.315313   \n28  0.360728     63.893221     9.516253       70.354955      15.642839   \n29  0.673963     55.585708    20.673400       62.361073      22.888275   \n30  0.653417     57.757004    19.867764       65.323740      22.401107   \n31  0.628325     59.153993    18.955033       67.345984      21.628257   \n32  0.602080     60.107457    18.077431       68.718008      20.760638   \n33  0.572708     59.624082    17.219157       67.984134      19.829306   \n34  0.583564     57.694033    17.522440       65.053532      21.057903   \n35  0.682670     53.926683    20.937119       61.466154      23.418681   \n36  0.023495     67.117157     2.180876       80.671241       1.000569   \n37  0.023501     67.725341     1.850006       80.889580       1.020508   \n38  0.027778     67.479633     1.639547       80.359702       1.166481   \n39  0.194547     64.378957     5.626853       75.627289       8.348169   \n40  0.409478     59.305896    11.341373       67.597410      17.773932   \n41  0.674059     50.742770    21.892341       59.901167      23.655655   \n42  0.658823     53.315866    21.228828       63.148800      23.304230   \n43  0.636203     55.231389    20.495852       65.346234      22.563879   \n44  0.612088     56.703336    19.776725       66.907616      21.730683   \n45  0.580806     57.408929    18.887688       66.807388      20.621745   \n46  0.578446     56.383943    18.330126       64.336658      21.176163   \n47  0.673236     52.656545    21.565106       60.811820      23.408145   \n48  0.012830     72.055484     0.784554       83.932587       0.649882   \n49  0.013711     72.149370     0.810250       83.764348       0.655411   \n50  0.033809     72.014375     0.990010       82.838593       1.522677   \n51  0.164971     70.135079     3.399416       78.781306       7.195614   \n52  0.370346     65.889755     9.035906       71.387758      16.131524   \n53  0.686798     57.961551    20.015809       62.994077      23.858967   \n54  0.662606     59.723316    19.031802       65.827806      23.156954   \n55  0.635335     61.026003    18.140484       67.747236      22.253673   \n56  0.607868     61.886208    17.275525       69.050499      21.303726   \n57  0.579229     61.261665    16.501380       68.035006      20.456959   \n58  0.585684     59.482351    16.710802       65.248626      21.403909   \n59  0.685043     55.896389    19.993290       61.596576      23.805249   \n\n    mean_f1_train  std_f1_train  mean_f1_val  std_f1_val  \n0        0.881785      0.005654     0.754430    0.003962  \n1        0.878310      0.009760     0.757455    0.012299  \n2        0.876271      0.008692     0.758931    0.011460  \n3        0.828278      0.083659     0.727154    0.056903  \n4        0.739389      0.193005     0.669061    0.127240  \n5        0.640302      0.283215     0.570275    0.250451  \n6        0.672284      0.273661     0.594345    0.239270  \n7        0.694280      0.262520     0.611319    0.228306  \n8        0.708747      0.250875     0.621693    0.217251  \n9        0.699167      0.239762     0.614613    0.207203  \n10       0.671101      0.245237     0.599881    0.203026  \n11       0.627610      0.275711     0.557799    0.239801  \n12       0.811308      0.008362     0.664787    0.005823  \n13       0.811321      0.007279     0.666611    0.007171  \n14       0.800896      0.016670     0.662219    0.011439  \n15       0.751580      0.086754     0.630598    0.055812  \n16       0.679587      0.163761     0.595991    0.085422  \n17       0.586325      0.256690     0.504586    0.219380  \n18       0.617256      0.249467     0.527081    0.210461  \n19       0.639975      0.241013     0.545022    0.202570  \n20       0.657006      0.232313     0.560969    0.196379  \n21       0.653655      0.220674     0.566869    0.187156  \n22       0.630522      0.222801     0.559650    0.179962  \n23       0.588664      0.254583     0.519160    0.218694  \n24       0.826631      0.009277     0.714694    0.008890  \n25       0.826210      0.006931     0.713868    0.007480  \n26       0.818665      0.012422     0.707843    0.012323  \n27       0.770146      0.084950     0.680688    0.048409  \n28       0.697595      0.164113     0.638587    0.095062  \n29       0.604692      0.256348     0.546041    0.225549  \n30       0.636881      0.250110     0.569011    0.216289  \n31       0.659031      0.241200     0.583903    0.206184  \n32       0.674229      0.231463     0.594184    0.196587  \n33       0.667585      0.220603     0.590174    0.186964  \n34       0.637320      0.231119     0.571981    0.187379  \n35       0.596121      0.260191     0.531046    0.225240  \n36       0.805536      0.010144     0.668982    0.021197  \n37       0.807827      0.010274     0.675478    0.018249  \n38       0.802527      0.011716     0.673000    0.016211  \n39       0.753948      0.085678     0.642936    0.054567  \n40       0.669750      0.185568     0.593853    0.109781  \n41       0.578482      0.265252     0.502270    0.228655  \n42       0.613764      0.260370     0.528564    0.221316  \n43       0.637829      0.251763     0.548161    0.213433  \n44       0.655054      0.242347     0.563376    0.205875  \n45       0.654885      0.229950     0.571124    0.196760  \n46       0.629266      0.233965     0.561356    0.190386  \n47       0.588282      0.262187     0.522276    0.224432  \n48       0.838400      0.006527     0.720647    0.007492  \n49       0.836791      0.006557     0.721526    0.008012  \n50       0.827552      0.015227     0.720188    0.009959  \n51       0.786153      0.073349     0.701487    0.033779  \n52       0.708343      0.168921     0.659317    0.089739  \n53       0.612546      0.264160     0.570088    0.217341  \n54       0.643240      0.255887     0.588873    0.206459  \n55       0.664217      0.245756     0.602901    0.196729  \n56       0.678644      0.235279     0.612221    0.187346  \n57       0.669173      0.225175     0.606719    0.178565  \n58       0.640269      0.233360     0.590158    0.178144  \n59       0.598251      0.263349     0.550737    0.215149  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>cfg</th>\n      <th>fold</th>\n      <th>loss_test</th>\n      <th>acc_test</th>\n      <th>f1_test</th>\n      <th>mean_loss</th>\n      <th>std_loss</th>\n      <th>mean_acc_val</th>\n      <th>std_acc_val</th>\n      <th>mean_acc_train</th>\n      <th>std_acc_train</th>\n      <th>mean_f1_train</th>\n      <th>std_f1_train</th>\n      <th>mean_f1_val</th>\n      <th>std_f1_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>18.940403</td>\n      <td>13.612167</td>\n      <td>0.148006</td>\n      <td>0.289398</td>\n      <td>0.013900</td>\n      <td>75.375842</td>\n      <td>0.475101</td>\n      <td>88.254775</td>\n      <td>0.562407</td>\n      <td>0.881785</td>\n      <td>0.005654</td>\n      <td>0.754430</td>\n      <td>0.003962</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13.517536</td>\n      <td>22.813688</td>\n      <td>0.216087</td>\n      <td>0.296447</td>\n      <td>0.022876</td>\n      <td>75.671540</td>\n      <td>1.257495</td>\n      <td>87.909500</td>\n      <td>0.968884</td>\n      <td>0.878310</td>\n      <td>0.009760</td>\n      <td>0.757455</td>\n      <td>0.012299</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>18.105448</td>\n      <td>12.433460</td>\n      <td>0.142572</td>\n      <td>0.301010</td>\n      <td>0.020293</td>\n      <td>75.823471</td>\n      <td>1.143876</td>\n      <td>87.699934</td>\n      <td>0.865473</td>\n      <td>0.876271</td>\n      <td>0.008692</td>\n      <td>0.758931</td>\n      <td>0.011460</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.751302</td>\n      <td>67.984791</td>\n      <td>0.684068</td>\n      <td>0.410880</td>\n      <td>0.191540</td>\n      <td>72.575773</td>\n      <td>5.793029</td>\n      <td>83.027949</td>\n      <td>8.142960</td>\n      <td>0.828278</td>\n      <td>0.083659</td>\n      <td>0.727154</td>\n      <td>0.056903</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1.168189</td>\n      <td>49.581749</td>\n      <td>0.505397</td>\n      <td>0.611775</td>\n      <td>0.437051</td>\n      <td>66.671148</td>\n      <td>12.934831</td>\n      <td>74.474675</td>\n      <td>18.603783</td>\n      <td>0.739389</td>\n      <td>0.193005</td>\n      <td>0.669061</td>\n      <td>0.127240</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2.254341</td>\n      <td>18.631179</td>\n      <td>0.154145</td>\n      <td>0.886728</td>\n      <td>0.732925</td>\n      <td>57.278686</td>\n      <td>24.252981</td>\n      <td>65.782976</td>\n      <td>25.818213</td>\n      <td>0.640302</td>\n      <td>0.283215</td>\n      <td>0.570275</td>\n      <td>0.250451</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>6</td>\n      <td>1</td>\n      <td>12.516399</td>\n      <td>19.201521</td>\n      <td>0.186588</td>\n      <td>0.806154</td>\n      <td>0.706682</td>\n      <td>59.659431</td>\n      <td>23.200582</td>\n      <td>68.741819</td>\n      <td>24.977831</td>\n      <td>0.672284</td>\n      <td>0.273661</td>\n      <td>0.594345</td>\n      <td>0.239270</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>9.610622</td>\n      <td>20.152091</td>\n      <td>0.193252</td>\n      <td>0.750074</td>\n      <td>0.677493</td>\n      <td>61.345407</td>\n      <td>22.158502</td>\n      <td>70.762288</td>\n      <td>23.968632</td>\n      <td>0.694280</td>\n      <td>0.262520</td>\n      <td>0.611319</td>\n      <td>0.228306</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8.661695</td>\n      <td>25.057034</td>\n      <td>0.219253</td>\n      <td>0.712597</td>\n      <td>0.647498</td>\n      <td>62.370921</td>\n      <td>21.092658</td>\n      <td>72.070202</td>\n      <td>22.899502</td>\n      <td>0.708747</td>\n      <td>0.250875</td>\n      <td>0.621693</td>\n      <td>0.217251</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2.770374</td>\n      <td>25.893536</td>\n      <td>0.240637</td>\n      <td>0.730237</td>\n      <td>0.616622</td>\n      <td>61.641182</td>\n      <td>20.130258</td>\n      <td>71.050573</td>\n      <td>21.942100</td>\n      <td>0.699167</td>\n      <td>0.239762</td>\n      <td>0.614613</td>\n      <td>0.207203</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>10</td>\n      <td>1</td>\n      <td>2.178082</td>\n      <td>28.022814</td>\n      <td>0.224635</td>\n      <td>0.788966</td>\n      <td>0.616590</td>\n      <td>60.105156</td>\n      <td>19.802989</td>\n      <td>68.309591</td>\n      <td>22.646509</td>\n      <td>0.671101</td>\n      <td>0.245237</td>\n      <td>0.599881</td>\n      <td>0.203026</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>11</td>\n      <td>1</td>\n      <td>2.289579</td>\n      <td>19.125475</td>\n      <td>0.148035</td>\n      <td>0.912474</td>\n      <td>0.718543</td>\n      <td>56.219784</td>\n      <td>22.985344</td>\n      <td>64.405776</td>\n      <td>25.264968</td>\n      <td>0.627610</td>\n      <td>0.275711</td>\n      <td>0.557799</td>\n      <td>0.239801</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0</td>\n      <td>2</td>\n      <td>5.828178</td>\n      <td>22.509506</td>\n      <td>0.191131</td>\n      <td>0.440478</td>\n      <td>0.017572</td>\n      <td>66.565125</td>\n      <td>0.532008</td>\n      <td>81.254468</td>\n      <td>0.825879</td>\n      <td>0.811308</td>\n      <td>0.008362</td>\n      <td>0.664787</td>\n      <td>0.005823</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5.978181</td>\n      <td>19.695817</td>\n      <td>0.150226</td>\n      <td>0.440467</td>\n      <td>0.014978</td>\n      <td>66.798837</td>\n      <td>0.596181</td>\n      <td>81.240863</td>\n      <td>0.712141</td>\n      <td>0.811321</td>\n      <td>0.007279</td>\n      <td>0.666611</td>\n      <td>0.007171</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3.269951</td>\n      <td>30.684411</td>\n      <td>0.281673</td>\n      <td>0.463411</td>\n      <td>0.036441</td>\n      <td>66.380344</td>\n      <td>1.100915</td>\n      <td>80.200721</td>\n      <td>1.653451</td>\n      <td>0.800896</td>\n      <td>0.016670</td>\n      <td>0.662219</td>\n      <td>0.011439</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.945817</td>\n      <td>58.821293</td>\n      <td>0.588730</td>\n      <td>0.576282</td>\n      <td>0.198349</td>\n      <td>63.183201</td>\n      <td>5.635736</td>\n      <td>75.401871</td>\n      <td>8.446124</td>\n      <td>0.751580</td>\n      <td>0.086754</td>\n      <td>0.630598</td>\n      <td>0.055812</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1.097103</td>\n      <td>53.117871</td>\n      <td>0.538862</td>\n      <td>0.734099</td>\n      <td>0.362491</td>\n      <td>59.671546</td>\n      <td>8.654326</td>\n      <td>68.577224</td>\n      <td>15.622986</td>\n      <td>0.679587</td>\n      <td>0.163761</td>\n      <td>0.595991</td>\n      <td>0.085422</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2.280688</td>\n      <td>19.809886</td>\n      <td>0.171600</td>\n      <td>0.987963</td>\n      <td>0.657070</td>\n      <td>50.940175</td>\n      <td>21.130167</td>\n      <td>60.606331</td>\n      <td>22.831350</td>\n      <td>0.586325</td>\n      <td>0.256690</td>\n      <td>0.504586</td>\n      <td>0.219380</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>6</td>\n      <td>2</td>\n      <td>4.381033</td>\n      <td>23.840304</td>\n      <td>0.177178</td>\n      <td>0.911900</td>\n      <td>0.636284</td>\n      <td>53.140174</td>\n      <td>20.292666</td>\n      <td>63.435018</td>\n      <td>22.248174</td>\n      <td>0.617256</td>\n      <td>0.249467</td>\n      <td>0.527081</td>\n      <td>0.210461</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>7</td>\n      <td>2</td>\n      <td>5.283458</td>\n      <td>22.547529</td>\n      <td>0.157092</td>\n      <td>0.856075</td>\n      <td>0.613310</td>\n      <td>54.892082</td>\n      <td>19.546129</td>\n      <td>65.507924</td>\n      <td>21.526086</td>\n      <td>0.639975</td>\n      <td>0.241013</td>\n      <td>0.545022</td>\n      <td>0.202570</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3.831899</td>\n      <td>32.091255</td>\n      <td>0.258347</td>\n      <td>0.813936</td>\n      <td>0.590458</td>\n      <td>56.451260</td>\n      <td>18.963056</td>\n      <td>67.051285</td>\n      <td>20.762889</td>\n      <td>0.657006</td>\n      <td>0.232313</td>\n      <td>0.560969</td>\n      <td>0.196379</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>9</td>\n      <td>2</td>\n      <td>3.871399</td>\n      <td>23.536122</td>\n      <td>0.176768</td>\n      <td>0.819556</td>\n      <td>0.560516</td>\n      <td>56.974183</td>\n      <td>18.059832</td>\n      <td>66.650866</td>\n      <td>19.739054</td>\n      <td>0.653655</td>\n      <td>0.220674</td>\n      <td>0.566869</td>\n      <td>0.187156</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>10</td>\n      <td>2</td>\n      <td>1.055093</td>\n      <td>56.425856</td>\n      <td>0.571810</td>\n      <td>0.867215</td>\n      <td>0.555382</td>\n      <td>56.200553</td>\n      <td>17.400038</td>\n      <td>64.408098</td>\n      <td>20.115798</td>\n      <td>0.630522</td>\n      <td>0.222801</td>\n      <td>0.559650</td>\n      <td>0.179962</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>11</td>\n      <td>2</td>\n      <td>2.296078</td>\n      <td>16.197719</td>\n      <td>0.164221</td>\n      <td>0.982693</td>\n      <td>0.655311</td>\n      <td>52.369068</td>\n      <td>20.976534</td>\n      <td>60.876323</td>\n      <td>22.543751</td>\n      <td>0.588664</td>\n      <td>0.254583</td>\n      <td>0.519160</td>\n      <td>0.218694</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.498692</td>\n      <td>79.193610</td>\n      <td>0.791973</td>\n      <td>0.402095</td>\n      <td>0.020770</td>\n      <td>71.527192</td>\n      <td>0.844426</td>\n      <td>82.760444</td>\n      <td>0.924812</td>\n      <td>0.826631</td>\n      <td>0.009277</td>\n      <td>0.714694</td>\n      <td>0.008890</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7.262911</td>\n      <td>22.936478</td>\n      <td>0.176534</td>\n      <td>0.402557</td>\n      <td>0.015134</td>\n      <td>71.453508</td>\n      <td>0.706731</td>\n      <td>82.724424</td>\n      <td>0.688173</td>\n      <td>0.826210</td>\n      <td>0.006931</td>\n      <td>0.713868</td>\n      <td>0.007480</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0.579616</td>\n      <td>74.971472</td>\n      <td>0.750021</td>\n      <td>0.420268</td>\n      <td>0.028524</td>\n      <td>70.831526</td>\n      <td>1.255325</td>\n      <td>81.968118</td>\n      <td>1.241464</td>\n      <td>0.818665</td>\n      <td>0.012422</td>\n      <td>0.707843</td>\n      <td>0.012323</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.780494</td>\n      <td>65.994675</td>\n      <td>0.662866</td>\n      <td>0.528486</td>\n      <td>0.189604</td>\n      <td>68.102729</td>\n      <td>4.863261</td>\n      <td>77.220625</td>\n      <td>8.315313</td>\n      <td>0.770146</td>\n      <td>0.084950</td>\n      <td>0.680688</td>\n      <td>0.048409</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.030025</td>\n      <td>28.527957</td>\n      <td>0.255888</td>\n      <td>0.687300</td>\n      <td>0.360728</td>\n      <td>63.893221</td>\n      <td>9.516253</td>\n      <td>70.354955</td>\n      <td>15.642839</td>\n      <td>0.697595</td>\n      <td>0.164113</td>\n      <td>0.638587</td>\n      <td>0.095062</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2.291271</td>\n      <td>12.248003</td>\n      <td>0.107747</td>\n      <td>0.950278</td>\n      <td>0.673963</td>\n      <td>55.585708</td>\n      <td>20.673400</td>\n      <td>62.361073</td>\n      <td>22.888275</td>\n      <td>0.604692</td>\n      <td>0.256348</td>\n      <td>0.546041</td>\n      <td>0.225549</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>6</td>\n      <td>3</td>\n      <td>5.458804</td>\n      <td>22.898440</td>\n      <td>0.178341</td>\n      <td>0.871154</td>\n      <td>0.653417</td>\n      <td>57.757004</td>\n      <td>19.867764</td>\n      <td>65.323740</td>\n      <td>22.401107</td>\n      <td>0.636881</td>\n      <td>0.250110</td>\n      <td>0.569011</td>\n      <td>0.216289</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3.692444</td>\n      <td>32.027387</td>\n      <td>0.277362</td>\n      <td>0.816153</td>\n      <td>0.628325</td>\n      <td>59.153993</td>\n      <td>18.955033</td>\n      <td>67.345984</td>\n      <td>21.628257</td>\n      <td>0.659031</td>\n      <td>0.241200</td>\n      <td>0.583903</td>\n      <td>0.206184</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>8</td>\n      <td>3</td>\n      <td>4.457298</td>\n      <td>27.577025</td>\n      <td>0.209407</td>\n      <td>0.778215</td>\n      <td>0.602080</td>\n      <td>60.107457</td>\n      <td>18.077431</td>\n      <td>68.718008</td>\n      <td>20.760638</td>\n      <td>0.674229</td>\n      <td>0.231463</td>\n      <td>0.594184</td>\n      <td>0.196587</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>9</td>\n      <td>3</td>\n      <td>2.464701</td>\n      <td>30.315709</td>\n      <td>0.264350</td>\n      <td>0.790917</td>\n      <td>0.572708</td>\n      <td>59.624082</td>\n      <td>17.219157</td>\n      <td>67.984134</td>\n      <td>19.829306</td>\n      <td>0.667585</td>\n      <td>0.220603</td>\n      <td>0.590174</td>\n      <td>0.186964</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1.924381</td>\n      <td>30.962343</td>\n      <td>0.267599</td>\n      <td>0.855967</td>\n      <td>0.583564</td>\n      <td>57.694033</td>\n      <td>17.522440</td>\n      <td>65.053532</td>\n      <td>21.057903</td>\n      <td>0.637320</td>\n      <td>0.231119</td>\n      <td>0.571981</td>\n      <td>0.187379</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>11</td>\n      <td>3</td>\n      <td>2.296966</td>\n      <td>18.372005</td>\n      <td>0.117269</td>\n      <td>0.974238</td>\n      <td>0.682670</td>\n      <td>53.926683</td>\n      <td>20.937119</td>\n      <td>61.466154</td>\n      <td>23.418681</td>\n      <td>0.596121</td>\n      <td>0.260191</td>\n      <td>0.531046</td>\n      <td>0.225240</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>0</td>\n      <td>4</td>\n      <td>7.403112</td>\n      <td>16.964625</td>\n      <td>0.119128</td>\n      <td>0.454879</td>\n      <td>0.023495</td>\n      <td>67.117157</td>\n      <td>2.180876</td>\n      <td>80.671241</td>\n      <td>1.000569</td>\n      <td>0.805536</td>\n      <td>0.010144</td>\n      <td>0.668982</td>\n      <td>0.021197</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4.995937</td>\n      <td>24.724230</td>\n      <td>0.219541</td>\n      <td>0.449225</td>\n      <td>0.023501</td>\n      <td>67.725341</td>\n      <td>1.850006</td>\n      <td>80.889580</td>\n      <td>1.020508</td>\n      <td>0.807827</td>\n      <td>0.010274</td>\n      <td>0.675478</td>\n      <td>0.018249</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>38</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0.658782</td>\n      <td>72.917459</td>\n      <td>0.728823</td>\n      <td>0.462066</td>\n      <td>0.027778</td>\n      <td>67.479633</td>\n      <td>1.639547</td>\n      <td>80.359702</td>\n      <td>1.166481</td>\n      <td>0.802527</td>\n      <td>0.011716</td>\n      <td>0.673000</td>\n      <td>0.016211</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3.914467</td>\n      <td>19.969570</td>\n      <td>0.155608</td>\n      <td>0.572289</td>\n      <td>0.194547</td>\n      <td>64.378957</td>\n      <td>5.626853</td>\n      <td>75.627289</td>\n      <td>8.348169</td>\n      <td>0.753948</td>\n      <td>0.085678</td>\n      <td>0.642936</td>\n      <td>0.054567</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>40</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1.882785</td>\n      <td>27.615063</td>\n      <td>0.224291</td>\n      <td>0.756923</td>\n      <td>0.409478</td>\n      <td>59.305896</td>\n      <td>11.341373</td>\n      <td>67.597410</td>\n      <td>17.773932</td>\n      <td>0.669750</td>\n      <td>0.185568</td>\n      <td>0.593853</td>\n      <td>0.109781</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>41</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2.257028</td>\n      <td>15.252948</td>\n      <td>0.135088</td>\n      <td>1.007771</td>\n      <td>0.674059</td>\n      <td>50.742770</td>\n      <td>21.892341</td>\n      <td>59.901167</td>\n      <td>23.655655</td>\n      <td>0.578482</td>\n      <td>0.265252</td>\n      <td>0.502270</td>\n      <td>0.228655</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>42</td>\n      <td>6</td>\n      <td>4</td>\n      <td>7.386781</td>\n      <td>17.991632</td>\n      <td>0.150818</td>\n      <td>0.921627</td>\n      <td>0.658823</td>\n      <td>53.315866</td>\n      <td>21.228828</td>\n      <td>63.148800</td>\n      <td>23.304230</td>\n      <td>0.613764</td>\n      <td>0.260370</td>\n      <td>0.528564</td>\n      <td>0.221316</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>43</td>\n      <td>7</td>\n      <td>4</td>\n      <td>6.499929</td>\n      <td>16.774439</td>\n      <td>0.146436</td>\n      <td>0.861984</td>\n      <td>0.636203</td>\n      <td>55.231389</td>\n      <td>20.495852</td>\n      <td>65.346234</td>\n      <td>22.563879</td>\n      <td>0.637829</td>\n      <td>0.251763</td>\n      <td>0.548161</td>\n      <td>0.213433</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>44</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0.564435</td>\n      <td>75.275770</td>\n      <td>0.752554</td>\n      <td>0.818962</td>\n      <td>0.612088</td>\n      <td>56.703336</td>\n      <td>19.776725</td>\n      <td>66.907616</td>\n      <td>21.730683</td>\n      <td>0.655054</td>\n      <td>0.242347</td>\n      <td>0.563376</td>\n      <td>0.205875</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>45</td>\n      <td>9</td>\n      <td>4</td>\n      <td>4.230159</td>\n      <td>24.800304</td>\n      <td>0.194789</td>\n      <td>0.816713</td>\n      <td>0.580806</td>\n      <td>57.408929</td>\n      <td>18.887688</td>\n      <td>66.807388</td>\n      <td>20.621745</td>\n      <td>0.654885</td>\n      <td>0.229950</td>\n      <td>0.571124</td>\n      <td>0.196760</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>46</td>\n      <td>10</td>\n      <td>4</td>\n      <td>2.133507</td>\n      <td>32.293648</td>\n      <td>0.255840</td>\n      <td>0.869075</td>\n      <td>0.578446</td>\n      <td>56.383943</td>\n      <td>18.330126</td>\n      <td>64.336658</td>\n      <td>21.176163</td>\n      <td>0.629266</td>\n      <td>0.233965</td>\n      <td>0.561356</td>\n      <td>0.190386</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>11</td>\n      <td>4</td>\n      <td>2.289704</td>\n      <td>22.365919</td>\n      <td>0.122689</td>\n      <td>0.984491</td>\n      <td>0.673236</td>\n      <td>52.656545</td>\n      <td>21.565106</td>\n      <td>60.811820</td>\n      <td>23.408145</td>\n      <td>0.588282</td>\n      <td>0.262187</td>\n      <td>0.522276</td>\n      <td>0.224432</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>48</td>\n      <td>0</td>\n      <td>5</td>\n      <td>7.434802</td>\n      <td>24.381894</td>\n      <td>0.176671</td>\n      <td>0.379040</td>\n      <td>0.012830</td>\n      <td>72.055484</td>\n      <td>0.784554</td>\n      <td>83.932587</td>\n      <td>0.649882</td>\n      <td>0.838400</td>\n      <td>0.006527</td>\n      <td>0.720647</td>\n      <td>0.007492</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>49</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.514022</td>\n      <td>78.965386</td>\n      <td>0.789361</td>\n      <td>0.383768</td>\n      <td>0.013711</td>\n      <td>72.149370</td>\n      <td>0.810250</td>\n      <td>83.764348</td>\n      <td>0.655411</td>\n      <td>0.836791</td>\n      <td>0.006557</td>\n      <td>0.721526</td>\n      <td>0.008012</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>50</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7.100224</td>\n      <td>13.427159</td>\n      <td>0.097930</td>\n      <td>0.404577</td>\n      <td>0.033809</td>\n      <td>72.014375</td>\n      <td>0.990010</td>\n      <td>82.838593</td>\n      <td>1.522677</td>\n      <td>0.827552</td>\n      <td>0.015227</td>\n      <td>0.720188</td>\n      <td>0.009959</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>51</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3.982442</td>\n      <td>17.839483</td>\n      <td>0.140550</td>\n      <td>0.497902</td>\n      <td>0.164971</td>\n      <td>70.135079</td>\n      <td>3.399416</td>\n      <td>78.781306</td>\n      <td>7.195614</td>\n      <td>0.786153</td>\n      <td>0.073349</td>\n      <td>0.701487</td>\n      <td>0.033779</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>52</td>\n      <td>4</td>\n      <td>5</td>\n      <td>3.074195</td>\n      <td>17.230886</td>\n      <td>0.109658</td>\n      <td>0.667668</td>\n      <td>0.370346</td>\n      <td>65.889755</td>\n      <td>9.035906</td>\n      <td>71.387758</td>\n      <td>16.131524</td>\n      <td>0.708343</td>\n      <td>0.168921</td>\n      <td>0.659317</td>\n      <td>0.089739</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>53</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2.298211</td>\n      <td>5.325219</td>\n      <td>0.038804</td>\n      <td>0.935022</td>\n      <td>0.686798</td>\n      <td>57.961551</td>\n      <td>20.015809</td>\n      <td>62.994077</td>\n      <td>23.858967</td>\n      <td>0.612546</td>\n      <td>0.264160</td>\n      <td>0.570088</td>\n      <td>0.217341</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>54</td>\n      <td>6</td>\n      <td>5</td>\n      <td>4.851910</td>\n      <td>21.681248</td>\n      <td>0.157890</td>\n      <td>0.859018</td>\n      <td>0.662606</td>\n      <td>59.723316</td>\n      <td>19.031802</td>\n      <td>65.827806</td>\n      <td>23.156954</td>\n      <td>0.643240</td>\n      <td>0.255887</td>\n      <td>0.588873</td>\n      <td>0.206459</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>55</td>\n      <td>7</td>\n      <td>5</td>\n      <td>6.053369</td>\n      <td>12.818562</td>\n      <td>0.105500</td>\n      <td>0.806396</td>\n      <td>0.635335</td>\n      <td>61.026003</td>\n      <td>18.140484</td>\n      <td>67.747236</td>\n      <td>22.253673</td>\n      <td>0.664217</td>\n      <td>0.245756</td>\n      <td>0.602901</td>\n      <td>0.196729</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>56</td>\n      <td>8</td>\n      <td>5</td>\n      <td>7.487917</td>\n      <td>11.639407</td>\n      <td>0.079087</td>\n      <td>0.769866</td>\n      <td>0.607868</td>\n      <td>61.886208</td>\n      <td>17.275525</td>\n      <td>69.050499</td>\n      <td>21.303726</td>\n      <td>0.678644</td>\n      <td>0.235279</td>\n      <td>0.612221</td>\n      <td>0.187346</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>57</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2.688849</td>\n      <td>29.478889</td>\n      <td>0.252266</td>\n      <td>0.787365</td>\n      <td>0.579229</td>\n      <td>61.261665</td>\n      <td>16.501380</td>\n      <td>68.035006</td>\n      <td>20.456959</td>\n      <td>0.669173</td>\n      <td>0.225175</td>\n      <td>0.606719</td>\n      <td>0.178565</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>58</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1.193308</td>\n      <td>49.258273</td>\n      <td>0.504290</td>\n      <td>0.848962</td>\n      <td>0.585684</td>\n      <td>59.482351</td>\n      <td>16.710802</td>\n      <td>65.248626</td>\n      <td>21.403909</td>\n      <td>0.640269</td>\n      <td>0.233360</td>\n      <td>0.590158</td>\n      <td>0.178144</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>59</td>\n      <td>11</td>\n      <td>5</td>\n      <td>2.291784</td>\n      <td>27.729175</td>\n      <td>0.160606</td>\n      <td>0.967607</td>\n      <td>0.685043</td>\n      <td>55.896389</td>\n      <td>19.993290</td>\n      <td>61.596576</td>\n      <td>23.805249</td>\n      <td>0.598251</td>\n      <td>0.263349</td>\n      <td>0.550737</td>\n      <td>0.215149</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scikit learn best cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def calculate_statistics_sklearn(df: pd.DataFrame, model: str) -> Dict:\n",
    "    res = {'f1': mu_confidence_interval(df[df['model'] == model]['f1_test']),\n",
    "           'loss': mu_confidence_interval(df[df['model'] == model]['loss_test']),\n",
    "           'acc': mu_confidence_interval(df[df['model'] == model]['acc_test']),\n",
    "           'conf': df[df['model'] == model]['cfg'].unique()}\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tree based"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration random_forest_classifier mean metrics:\n",
      "f1_score: 0.609756989767005 ±0.006529683898881055\n",
      "loss: 0.39225757744490736 ±0.00712946750658302\n",
      "acc: 0.6077424225550925 ±0.007129467506583035\n",
      "\n",
      "Best hyperparams configuration:\n",
      "[\"{'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 700}\"]\n"
     ]
    }
   ],
   "source": [
    "res_random_forest = calculate_statistics_sklearn(tree_res, 'random_forest_classifier')\n",
    "df_test_metric = summary_statistics_model(df_test_metric, res_random_forest, 'random_forest_classifier')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decision tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration decision_tree_classifier mean metrics:\n",
      "f1_score: 0.6402913493313054 ±0.004216781363865863\n",
      "loss: 0.36008162828469237 ±0.004052145718922026\n",
      "acc: 0.6399183717153076 ±0.004052145718922028\n",
      "\n",
      "Best hyperparams configuration:\n",
      "[\"{'criterion': 'entropy', 'max_depth': 15}\"]\n"
     ]
    }
   ],
   "source": [
    "res_decision_tree = calculate_statistics_sklearn(tree_res, 'decision_tree_classifier')\n",
    "df_test_metric = summary_statistics_model(df_test_metric, res_decision_tree, 'decision_tree_classifier')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive bayes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gaussian naive bayes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration gaussian_nb mean metrics:\n",
      "f1_score: 0.4526802764969494 ±0.010686051270129714\n",
      "loss: 0.5481864029029817 ±0.010409238716856704\n",
      "acc: 0.4518135970970182 ±0.010409238716856686\n",
      "\n",
      "Best hyperparams configuration:\n",
      "[\"{'var_smoothing': 8.111308307896872e-07}\"]\n"
     ]
    }
   ],
   "source": [
    "res_gaussian_nb = calculate_statistics_sklearn(naive_res, 'gaussian_nb')\n",
    "df_test_metric = summary_statistics_model(df_test_metric, res_gaussian_nb, 'gaussian_nb')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### QDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration qda mean metrics:\n",
      "f1_score: 0.5217235201683785 ±0.007963795942101407\n",
      "loss: 0.4649740608914607 ±0.00827922547607728\n",
      "acc: 0.5350259391085392 ±0.00827922547607726\n",
      "\n",
      "Best hyperparams configuration:\n",
      "[\"{'reg_param': 0.001, 'tol': 0.0001}\"]\n"
     ]
    }
   ],
   "source": [
    "res_qda = calculate_statistics_sklearn(naive_res, 'qda')\n",
    "df_test_metric = summary_statistics_model(df_test_metric, res_qda, 'qda')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration svc mean metrics:\n",
      "f1_score: 0.8286206857647119 ±0.004227564469616818\n",
      "loss: 0.17076133850717423 ±0.004051273714411658\n",
      "acc: 0.8292386614928257 ±0.004051273714411657\n",
      "\n",
      "Best hyperparams configuration:\n",
      "[\"{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\"]\n"
     ]
    }
   ],
   "source": [
    "res_svm = calculate_statistics_sklearn(svm_res, 'svc')\n",
    "df_test_metric = summary_statistics_model(df_test_metric, res_svm, 'svc')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "                      model     f1_mu    acc_mu   loss_mu     f1_ci    acc_ci  \\\n0                       mlp  0.861018  0.860804  0.357536  0.009781  0.009830   \n1  random_forest_classifier  0.609757  0.607742  0.392258  0.006530  0.007129   \n2  decision_tree_classifier  0.640291  0.639918  0.360082  0.004217  0.004052   \n3               gaussian_nb  0.452680  0.451814  0.548186  0.010686  0.010409   \n4                       qda  0.521724  0.535026  0.464974  0.007964  0.008279   \n5                       svc  0.828621  0.829239  0.170761  0.004228  0.004051   \n\n    loss_ci  \n0  0.016819  \n1  0.007129  \n2  0.004052  \n3  0.010409  \n4  0.008279  \n5  0.004051  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>f1_mu</th>\n      <th>acc_mu</th>\n      <th>loss_mu</th>\n      <th>f1_ci</th>\n      <th>acc_ci</th>\n      <th>loss_ci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mlp</td>\n      <td>0.861018</td>\n      <td>0.860804</td>\n      <td>0.357536</td>\n      <td>0.009781</td>\n      <td>0.009830</td>\n      <td>0.016819</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>random_forest_classifier</td>\n      <td>0.609757</td>\n      <td>0.607742</td>\n      <td>0.392258</td>\n      <td>0.006530</td>\n      <td>0.007129</td>\n      <td>0.007129</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>decision_tree_classifier</td>\n      <td>0.640291</td>\n      <td>0.639918</td>\n      <td>0.360082</td>\n      <td>0.004217</td>\n      <td>0.004052</td>\n      <td>0.004052</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gaussian_nb</td>\n      <td>0.452680</td>\n      <td>0.451814</td>\n      <td>0.548186</td>\n      <td>0.010686</td>\n      <td>0.010409</td>\n      <td>0.010409</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>qda</td>\n      <td>0.521724</td>\n      <td>0.535026</td>\n      <td>0.464974</td>\n      <td>0.007964</td>\n      <td>0.008279</td>\n      <td>0.008279</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>svc</td>\n      <td>0.828621</td>\n      <td>0.829239</td>\n      <td>0.170761</td>\n      <td>0.004228</td>\n      <td>0.004051</td>\n      <td>0.004051</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: export DataFrame\n",
    "df_test_metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.86101756, 0.86080399, 0.35753604]), array([0.60975699, 0.60774242, 0.39225758]), array([0.64029135, 0.63991837, 0.36008163]), array([0.45268028, 0.4518136 , 0.5481864 ]), array([0.52172352, 0.53502594, 0.46497406]), array([0.82862069, 0.82923866, 0.17076134])]\n",
      "[array([0.00978116, 0.00982962, 0.01681944]), array([0.00652968, 0.00712947, 0.00712947]), array([0.00421678, 0.00405215, 0.00405215]), array([0.01068605, 0.01040924, 0.01040924]), array([0.0079638 , 0.00827923, 0.00827923]), array([0.00422756, 0.00405127, 0.00405127])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# TODO: change function and params name? Return new list or use reference (it works)?\n",
    "def add_value_array(old_list: List, df_test: pd.DataFrame, col_name: str) -> None:\n",
    "    for model_name in df_test['model'].unique():\n",
    "        if col_name == 'metrics':\n",
    "            metric_value = df_test[df_test['model'] == model_name].iloc[:, 1:4].iloc[0]\n",
    "        else:\n",
    "            metric_value = df_test[df_test['model'] == model_name].iloc[:, 4:].iloc[0]\n",
    "\n",
    "        old_list.append(np.array(metric_value))\n",
    "\n",
    "\n",
    "metrics = []\n",
    "add_value_array(metrics, df_test_metric, 'metrics')\n",
    "print(metrics)\n",
    "\n",
    "y_errs = []\n",
    "add_value_array(y_errs, df_test_metric, 'interval')\n",
    "print(y_errs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "barplot_multiple_columns(groups=['f1', 'acc', 'loss (lower is better)'],\n",
    "                         elements_group=df_test_metric['model'].unique(), data=metrics, yerr=y_errs,\n",
    "                         title='Test metrics')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train & Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "df_test_metric_train=pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "def calculate_statistics_mlp_train(cfg:int, df: pd.DataFrame) -> dict:\n",
    "\n",
    "    res = {'train_score': mu_confidence_interval(df[df['cfg'] == cfg]['mean_f1_train']),\n",
    "               'val_score': mu_confidence_interval(df[df['cfg'] == cfg]['mean_f1_val']),\n",
    "               }\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration mlp mean metrics:\n",
      "train f1: 0.5429309605607313 ±0.00042095016144114497\n",
      "validation f1: 0.4958967938219824 ±0.0010892081090290028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_mlp_train = calculate_statistics_mlp_train(18,mlp_all)\n",
    "df_test_metric_train = summary_statistics_model(df_test_metric_train, res_mlp_train, 'mlp',train=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0  cfg  fold  loss_test   acc_test   f1_test  mean_loss  \\\n0             0    0     1   0.372040  85.285171  0.853134   0.306360   \n1             1    1     1   0.344320  85.171103  0.852068   0.302731   \n2             2    2     1   0.361184  85.285171  0.853100   0.304689   \n3             3    3     1   0.352550  85.817490  0.858861   0.306855   \n4             4    4     1   2.237197  10.798479  0.097864   0.673969   \n..          ...  ...   ...        ...        ...       ...        ...   \n955         955  187     5   0.481808  80.486877  0.805378   1.271628   \n956         956  188     5   2.295036  16.774439  0.102313   1.276690   \n957         957  189     5   2.289519  16.127805  0.101492   1.281689   \n958         958  190     5   2.261616  19.475086  0.166811   1.286323   \n959         959  191     5   2.267185  24.648155  0.194941   1.290910   \n\n     std_loss  mean_acc_val  std_acc_val  mean_acc_train  std_acc_train  \\\n0    0.017720     79.643519     0.993016       87.469802       0.759901   \n1    0.020831     79.783835     0.788934       87.632241       0.883383   \n2    0.018806     79.536465     0.954451       87.559346       0.787205   \n3    0.018824     79.500103     1.004205       87.455783       0.799693   \n4    0.734426     65.168832    28.681150       73.078158      28.773956   \n..        ...           ...          ...             ...            ...   \n955  0.869597     44.391021    33.047878       50.101529      33.251459   \n956  0.870067     44.191214    33.077768       49.910281      33.267216   \n957  0.870492     43.989620    33.109832       49.726107      33.276257   \n958  0.870557     43.820917    33.105664       49.545093      33.282774   \n959  0.870598     43.663094    33.094053       49.368514      33.285650   \n\n     mean_f1_train  std_f1_train  mean_f1_val  std_f1_val  \n0         0.873412      0.007689     0.797929    0.009758  \n1         0.875075      0.008986     0.799156    0.007691  \n2         0.874340      0.008016     0.796486    0.009295  \n3         0.873303      0.008139     0.795906    0.010032  \n4         0.713885      0.318954     0.647411    0.297186  \n..             ...           ...          ...         ...  \n955       0.466255      0.365353     0.429138    0.345926  \n956       0.464154      0.365526     0.427009    0.346253  \n957       0.462157      0.365599     0.424895    0.346572  \n958       0.460186      0.365651     0.423049    0.346610  \n959       0.458280      0.365650     0.421243    0.346637  \n\n[960 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>cfg</th>\n      <th>fold</th>\n      <th>loss_test</th>\n      <th>acc_test</th>\n      <th>f1_test</th>\n      <th>mean_loss</th>\n      <th>std_loss</th>\n      <th>mean_acc_val</th>\n      <th>std_acc_val</th>\n      <th>mean_acc_train</th>\n      <th>std_acc_train</th>\n      <th>mean_f1_train</th>\n      <th>std_f1_train</th>\n      <th>mean_f1_val</th>\n      <th>std_f1_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.372040</td>\n      <td>85.285171</td>\n      <td>0.853134</td>\n      <td>0.306360</td>\n      <td>0.017720</td>\n      <td>79.643519</td>\n      <td>0.993016</td>\n      <td>87.469802</td>\n      <td>0.759901</td>\n      <td>0.873412</td>\n      <td>0.007689</td>\n      <td>0.797929</td>\n      <td>0.009758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.344320</td>\n      <td>85.171103</td>\n      <td>0.852068</td>\n      <td>0.302731</td>\n      <td>0.020831</td>\n      <td>79.783835</td>\n      <td>0.788934</td>\n      <td>87.632241</td>\n      <td>0.883383</td>\n      <td>0.875075</td>\n      <td>0.008986</td>\n      <td>0.799156</td>\n      <td>0.007691</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.361184</td>\n      <td>85.285171</td>\n      <td>0.853100</td>\n      <td>0.304689</td>\n      <td>0.018806</td>\n      <td>79.536465</td>\n      <td>0.954451</td>\n      <td>87.559346</td>\n      <td>0.787205</td>\n      <td>0.874340</td>\n      <td>0.008016</td>\n      <td>0.796486</td>\n      <td>0.009295</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.352550</td>\n      <td>85.817490</td>\n      <td>0.858861</td>\n      <td>0.306855</td>\n      <td>0.018824</td>\n      <td>79.500103</td>\n      <td>1.004205</td>\n      <td>87.455783</td>\n      <td>0.799693</td>\n      <td>0.873303</td>\n      <td>0.008139</td>\n      <td>0.795906</td>\n      <td>0.010032</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2.237197</td>\n      <td>10.798479</td>\n      <td>0.097864</td>\n      <td>0.673969</td>\n      <td>0.734426</td>\n      <td>65.168832</td>\n      <td>28.681150</td>\n      <td>73.078158</td>\n      <td>28.773956</td>\n      <td>0.713885</td>\n      <td>0.318954</td>\n      <td>0.647411</td>\n      <td>0.297186</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>955</th>\n      <td>955</td>\n      <td>187</td>\n      <td>5</td>\n      <td>0.481808</td>\n      <td>80.486877</td>\n      <td>0.805378</td>\n      <td>1.271628</td>\n      <td>0.869597</td>\n      <td>44.391021</td>\n      <td>33.047878</td>\n      <td>50.101529</td>\n      <td>33.251459</td>\n      <td>0.466255</td>\n      <td>0.365353</td>\n      <td>0.429138</td>\n      <td>0.345926</td>\n    </tr>\n    <tr>\n      <th>956</th>\n      <td>956</td>\n      <td>188</td>\n      <td>5</td>\n      <td>2.295036</td>\n      <td>16.774439</td>\n      <td>0.102313</td>\n      <td>1.276690</td>\n      <td>0.870067</td>\n      <td>44.191214</td>\n      <td>33.077768</td>\n      <td>49.910281</td>\n      <td>33.267216</td>\n      <td>0.464154</td>\n      <td>0.365526</td>\n      <td>0.427009</td>\n      <td>0.346253</td>\n    </tr>\n    <tr>\n      <th>957</th>\n      <td>957</td>\n      <td>189</td>\n      <td>5</td>\n      <td>2.289519</td>\n      <td>16.127805</td>\n      <td>0.101492</td>\n      <td>1.281689</td>\n      <td>0.870492</td>\n      <td>43.989620</td>\n      <td>33.109832</td>\n      <td>49.726107</td>\n      <td>33.276257</td>\n      <td>0.462157</td>\n      <td>0.365599</td>\n      <td>0.424895</td>\n      <td>0.346572</td>\n    </tr>\n    <tr>\n      <th>958</th>\n      <td>958</td>\n      <td>190</td>\n      <td>5</td>\n      <td>2.261616</td>\n      <td>19.475086</td>\n      <td>0.166811</td>\n      <td>1.286323</td>\n      <td>0.870557</td>\n      <td>43.820917</td>\n      <td>33.105664</td>\n      <td>49.545093</td>\n      <td>33.282774</td>\n      <td>0.460186</td>\n      <td>0.365651</td>\n      <td>0.423049</td>\n      <td>0.346610</td>\n    </tr>\n    <tr>\n      <th>959</th>\n      <td>959</td>\n      <td>191</td>\n      <td>5</td>\n      <td>2.267185</td>\n      <td>24.648155</td>\n      <td>0.194941</td>\n      <td>1.290910</td>\n      <td>0.870598</td>\n      <td>43.663094</td>\n      <td>33.094053</td>\n      <td>49.368514</td>\n      <td>33.285650</td>\n      <td>0.458280</td>\n      <td>0.365650</td>\n      <td>0.421243</td>\n      <td>0.346637</td>\n    </tr>\n  </tbody>\n</table>\n<p>960 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_all\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "def calculate_statistics_sklearn_train(df: pd.DataFrame,first:bool=True) -> Dict:\n",
    "    if first:\n",
    "        res = {'train_score': mu_confidence_interval(df['mean_train_score'].iloc[0:5]),\n",
    "               'val_score': mu_confidence_interval(df['mean_test_score'].iloc[0:5]),\n",
    "               }\n",
    "    else:\n",
    "        res = {'train_score': mu_confidence_interval(df['mean_train_score'].iloc[5:10]),\n",
    "               'val_score': mu_confidence_interval(df['mean_test_score'].iloc[5:10]),\n",
    "               }\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration svm mean metrics:\n",
      "train f1: 0.9999782608688632 ±1.1833105435719024e-05\n",
      "validation f1: 0.9613343635021987 ±0.000923195543662202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_svm_train = calculate_statistics_sklearn_train(svm_val)\n",
    "df_test_metric_train = summary_statistics_model(df_test_metric_train, res_svm_train, 'svm',train=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration random_forest mean metrics:\n",
      "train f1: 0.7894708757467401 ±0.0028370536720411406\n",
      "validation f1: 0.7813933618457191 ±0.0025529991410781342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_random_forest_train = calculate_statistics_sklearn_train(tree_val)\n",
    "df_test_metric_train = summary_statistics_model(df_test_metric_train, res_random_forest_train, 'random_forest',train=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decision tree classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration decision_tree mean metrics:\n",
      "train f1: 0.9982448027541722 ±0.0001574523340800961\n",
      "validation f1: 0.8668832921611014 ±0.0011549731147417086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_decision_tree_train = calculate_statistics_sklearn_train(tree_val,first=False)\n",
    "df_test_metric_train = summary_statistics_model(df_test_metric_train, res_decision_tree_train, 'decision_tree',train=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GaussianNB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration gaussian_nb mean metrics:\n",
      "train f1: 0.7216627770722026 ±0.00336266744134676\n",
      "validation f1: 0.7074634406645496 ±0.003231430093703336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_gaussian_nb_train = calculate_statistics_sklearn_train(naive_val)\n",
    "df_test_metric_train = summary_statistics_model(df_test_metric_train, res_gaussian_nb_train, 'gaussian_nb',train=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### QDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration qda mean metrics:\n",
      "train f1: 0.9870351447504125 ±0.00035963628820091814\n",
      "validation f1: 0.8985859150139989 ±0.0007798478399543219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_qda_train = calculate_statistics_sklearn_train(naive_val,first=False)\n",
    "df_test_metric_train = summary_statistics_model(df_test_metric_train, res_qda_train, 'qda',train=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.99997826, 0.96133436]), array([0.78947088, 0.78139336]), array([0.9982448 , 0.86688329]), array([0.72166278, 0.70746344]), array([0.98703514, 0.89858592])]\n",
      "[array([1.18331054e-05, 9.23195544e-04]), array([0.00283705, 0.002553  ]), array([0.00015745, 0.00115497]), array([0.00336267, 0.00323143]), array([0.00035964, 0.00077985])]\n"
     ]
    }
   ],
   "source": [
    "# TODO: change function and params name? Return new list or use reference (it works)?\n",
    "def add_value_array_train(old_list: List, df_test: pd.DataFrame, col_name: str) -> None:\n",
    "    for model_name in df_test['model'].unique():\n",
    "        if col_name == 'metrics':\n",
    "            metric_value = df_test[df_test['model'] == model_name].iloc[:, 1:3].iloc[0]\n",
    "        else:\n",
    "            metric_value = df_test[df_test['model'] == model_name].iloc[:, 3:].iloc[0]\n",
    "\n",
    "        old_list.append(np.array(metric_value))\n",
    "\n",
    "\n",
    "metrics = []\n",
    "add_value_array_train(metrics, df_test_metric_train, 'metrics')\n",
    "print(metrics)\n",
    "\n",
    "y_errs = []\n",
    "add_value_array_train(y_errs, df_test_metric_train, 'interval')\n",
    "print(y_errs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [171]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mbarplot_multiple_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtraining\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvalidation\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                         \u001B[49m\u001B[43melements_group\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf_test_metric\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myerr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_errs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mtitle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTest metrics\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\movie-lens-mlp\\src\\visualization\\visualize.py:80\u001B[0m, in \u001B[0;36mbarplot_multiple_columns\u001B[1;34m(groups, elements_group, data, title, yerr, filename, save, label_count)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, elm \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(elements_group):\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;66;03m# df[df['balance']==elm][scores].to_numpy().squeeze() = [f1_random, f1_decision, f1_gaussian, f1_quadratic]\u001B[39;00m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m yerr:\n\u001B[1;32m---> 80\u001B[0m         ax\u001B[38;5;241m.\u001B[39mbar(x\u001B[38;5;241m=\u001B[39mrs[idx], height\u001B[38;5;241m=\u001B[39m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m, yerr\u001B[38;5;241m=\u001B[39myerr[idx], label\u001B[38;5;241m=\u001B[39melm, width\u001B[38;5;241m=\u001B[39mwidth)\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     82\u001B[0m         ax\u001B[38;5;241m.\u001B[39mbar(x\u001B[38;5;241m=\u001B[39mrs[idx], height\u001B[38;5;241m=\u001B[39mdata[idx], label\u001B[38;5;241m=\u001B[39melm, width\u001B[38;5;241m=\u001B[39mwidth)\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x720 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6kAAAJFCAYAAAA/LrH+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAozUlEQVR4nO3dbXDV5Z34/w9JSMPdn0UId6H6AGeHESoJNmGssTpqmc7usHQqjpQRdp0yi7IlMoAVS6sy3W0nCFgGtVpcO0Va7JQVpro+aPeBto6OTDaso0Xw5je6kjYl3FpoyDE3/weu0Rg0OZLkXCd5vWacJt9cyfmcXCb9vj3fnDOso6OjIwAAACABBbkeAAAAAD4gUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGUW5HuDTnDhxJtrbvYzr+PGj49ix07keg16yX/nHnuUX+5Vf7Fd+sV/5x57lF/v1voKCYTFu3KhP/HjSkdre3iFS/4/vQ36xX/nHnuUX+5Vf7Fd+sV/5x57lF/vVM5f7AgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyso7Uu+66K9avX/+pa15++eVYtGhRzJ49O+bNmxd79+79rPMBAAAwhPQ6Ujs6OmLr1q3xy1/+8lPXHT9+PJYtWxYzZ86MJ554IpYsWRLr16+P55577ryHBQAAYHAr6s2id955J77zne/E66+/HlOnTv3Utb/61a9i9OjRsX79+igoKIjp06fHgQMH4tFHH43q6uo+GRoAAIDBqVePpNbX18eUKVPiySefjGnTpn3q2rq6uqisrIyCgg+/dFVVVdTX10dHR8f5TQsAAMCg1qtHUhcsWBALFizo1RdsbGyMSy65pMuxiRMnRnNzc5w4cSIuuOCC7KcEAABgSOhVpGbj7NmzUVxc3OXYB+9nMpmsvtb48aP7bK6+drYlouRzA3d7paVjBuR2Bvp+DZSz7S1RUtD/d2zz5s2db69Zs6bfb2+g7tdQMFA/Y/QN+5Vf7Fd+sV/5x57lF/vVsz6P1JKSkm4x+sH7I0aMyOprHTt2Otrb07xEuLR0TBRelesp+l7bsxFNTX/J9Rh9rrR0TJTtu7z/b6jhZOebW/bt7v+bq3phUO7XQCstHeP7mEfsV36xX/nFfuUfe5Zf7Nf7CgqGfeoDkn0eqZMnT46mpqYux44cORIjR46MMWP8VwMGuUV/k+sJAAAgr2X9Oqk9ueyyy6Kurq7LkyS9+OKLMWfOnC5PpgQAAAAfd97VmMlkoqmpqfOS3oULF8bx48fj7rvvjjfffDMee+yxeOqpp2LZsmXnPSwAAACD23lH6v79+6O6ujr2798fERETJkyIRx55JA4cOBBf+9rXYufOnVFbWxuXXz4Afw8IAABAXsv6b1Ife+yxLu/PnTs3Dh061OVYeXl57N7d/08aAwxeY0ePjOIRhQN2ewP1THuZ5rY4dfqvA3JbAAD5qM+fOAmgLxSPKIxNs97J9Rh9bu0rn484nespAADS5ZmMAAAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZBTlegAAAHLvxz/eFqNGfS7OnGmJW29dmetxgCFMpAIAJGzU6FExckT/X/w2atTnOv+3tHRMv9/eX5vb48zpM/1+O0D+EakAAAkbOaIgCq8aiFta0/nWt3/d/7fW9mxBnDnd/7cD5B9/kwoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAySjK9QAAAAC5Mnb0yCgeUThgt1daOmZAbifT3BanTv91QG6rr4lUAABgyCoeURibZr2T6zH63NpXPh9xOtdTfDYu9wUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkFOV6AAAAGCxGjRseI4tKBuS2Nm/e3Pn2mjVr+v32/tp6Ns6ceK/fbwdEKgAA9JGRRSVRtu/ygbmxhpOdb27Zt7v/b67qhTgTIpX+J1IBACAfLfqbXE8A/cLfpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJ6FWktrW1xebNm6O6ujoqKiqipqYmjh49+onrX3jhhVi4cGGUl5fHddddF9u3b4+Ojo4+GxoAAIDBqVeRum3bttizZ0/U1tbGzp07o7GxMVauXHnOtW+//XbccsstcfXVV8eTTz4Za9eujQceeCB+8Ytf9OngAAAADD49Rmomk4kdO3bE6tWr44orroiZM2fGli1bor6+Purr67ut//3vfx8lJSXxrW99Kz7/+c/HV7/61bjqqqvi97//fb/cAQAAAAaPHiP14MGDcebMmaiqquo8Nm3atCgrK4u6urpu6y+44II4efJkPPXUU9He3h6vvfZa1NXVxaxZs/p2cgAAAAadHiO1sbExIiImTZrU5fjEiRM7P/ZR8+bNi4ULF8batWtj1qxZMX/+/KisrIwVK1b00cgAAAAMVkU9LWhubo6CgoIYPnx4l+PFxcXR0tLSbf27774bDQ0NsWzZsvi7v/u7eO211+IHP/hB3H///VFTU5PVcOPHj85qPX2jtHRMrkcgC/Yr/9iz8+d7mF/sF5/Evxv5x57ll3zdrx4jtaSkJNrb26O1tTWKij5cnslkYsSIEd3Wb9q0KQoLC2Pt2rUREXHJJZdEa2tr3HPPPbFkyZIYN25cr4c7dux0tLen+azA+brhvdHU9Jdcj9Dn7Ff+sWd8ktLSMb6HecR+nT+/D/PLYN6vCHuWb1Ldr4KCYZ/6gGSPl/tOmTIlIiKampq6HD9y5Ei3S4AjIl566aVuf386e/bseO+99+JPf/pTr4YGAABgaOoxUmfMmBGjRo2Kffv2dR47fPhwNDQ0RGVlZbf1kydPjkOHDnU59vrrr0dBQUFceOGFfTAyAAAAg1WPl/sWFxfH4sWLY+PGjTFu3LgYP358bNiwIaqqqqK8vDwymUycOnUqxo4dG8XFxbF06dJYvnx5PPjggzF//vx444034oc//GEsXrw4Ro/2N6a878c/3tb59q23nvs1dwEAgKGnx0iNiFi1alW0trbG7bffHq2trXHllVfGXXfdFRER+/fvj6VLl8aOHTti7ty5cdVVV8X9998fDz74YGzfvj0mTJgQN954Yyxfvrxf7wj55eGHH+h8W6QCAAAf6FWkFhUVxbp162LdunXdPjZ37txul/ded911cd111/XNhAys984O+B+PD+Y/VgcAALLTq0hlCBleEvG9Yf1+M6vLPxKmA3B78f00nyUaAADoSqSSE2vmpPl02ADA4OJ5MCD/iFQAAAYtz4MB+UekAgAw8DwPBvAJRCoAAAPP82AAn0CkAgAwaHkeDMg/BbkeAAAAAD4gUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEhGUa4HAPLDj3+8rfPtW29dmcNJAAAYzEQq0CsPP/xA59siFQCA/iJSIY91nD0bpaVjBvx2c3GbAAAMDSIV8tiwkpL487DRA3Jb/zzmc51vD8RtTuo43e+3AQBAekQq0Cu3/KUl1yMAADAEeHZfAAAAkiFSAQAASIbLfQEAgGR42TtEKgAAkAwve4dIBQAAepSLl77zsndDk0gFAAB6NGAvfTd1bOebXvZuaBKpAABAMv75L2dzPQI5JlIBAIBkeG12vAQNAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQjF5FaltbW2zevDmqq6ujoqIiampq4ujRo5+4vrGxMWpqaqKioiIuv/zyuOeee6K5ubnPhgYAAGBw6lWkbtu2Lfbs2RO1tbWxc+fOaGxsjJUrV55zbSaTiZtvvjlOnjwZu3btivvuuy+eeeaZuPfee/t0cAAAAAafop4WZDKZ2LFjR3z3u9+NK664IiIitmzZEtdee23U19fHnDlzuqx/8skno6mpKR5//PEYO3ZsRESsXLkydu3a1Q/jAwAAMJj0+EjqwYMH48yZM1FVVdV5bNq0aVFWVhZ1dXXd1j/33HPxpS99qTNQIyKuv/762L17dx+NDAAAwGDVY6Q2NjZGRMSkSZO6HJ84cWLnxz7qrbfeirKysvjRj34U11xzTVx77bVRW1sbLS0tfTQyAAAAg1WPl/s2NzdHQUFBDB8+vMvx4uLic4bn6dOnY/fu3fHlL385tm7dGn/+85/j+9//fhw7diw2btyY1XDjx4/Oaj1APigtHZPrEfKe72F+sV8AuZGvv397jNSSkpJob2+P1tbWKCr6cHkmk4kRI0Z0/4JFRTF27NjYuHFjFBYWxhe+8IVobW2N2267Le68884YN25cr4c7dux0tLd39Hr9QMrXDQdyr6npL7keIa+Vlo7xPcwj9uv8OecAPqtUf/8WFAz71Acke7zcd8qUKRER0dTU1OX4kSNHul0CHPH+ZcHTp0+PwsLCzmMXX3xxREQ0NDT0bmoAAACGpB4jdcaMGTFq1KjYt29f57HDhw9HQ0NDVFZWdlv/xS9+MV599dV47733Oo+99tprUVhYGGVlZX00NgAAAINRj5FaXFwcixcvjo0bN8bvfve7+MMf/hCrV6+OqqqqKC8vj0wmE01NTZHJZCIiYtGiRdHS0hJ33HFHvPnmm/H888/HvffeGwsWLMjqUl8AAACGnh4jNSJi1apVMX/+/Lj99ttj6dKlMXXq1Ni6dWtEROzfvz+qq6tj//79ERExYcKE+PnPfx6nTp2Kr3/967FmzZqYN29ebNiwof/uBQAAAINCj0+cFPH+kyGtW7cu1q1b1+1jc+fOjUOHDnU5dvHFF8e///u/982EAAAADBm9eiQVAAAABoJIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACSIVIBAABIhkgFAAAgGSIVAACAZIhUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBk9CpS29raYvPmzVFdXR0VFRVRU1MTR48e7dUNLF++PJYsWXJeQwIAADA09CpSt23bFnv27Ina2trYuXNnNDY2xsqVK3v8vMcffzyeeeaZ850RAACAIaLHSM1kMrFjx45YvXp1XHHFFTFz5szYsmVL1NfXR319/Sd+3ttvvx333XdfVFRU9OnAAAAADF49RurBgwfjzJkzUVVV1Xls2rRpUVZWFnV1def8nLa2trjjjjti2bJlMX369L6bFgAAgEGtx0htbGyMiIhJkyZ1OT5x4sTOj33cww8/HBER3/zmN893PgAAAIaQop4WNDc3R0FBQQwfPrzL8eLi4mhpaem2/pVXXomf/vSnsXv37igoOL8nDx4/fvR5fT5AikpLx+R6hLzne5hf7BdAbuTr798eI7WkpCTa29ujtbU1ioo+XJ7JZGLEiBFd1ra0tMS3v/3tWLVqVVx00UXnPdyxY6ejvb3jvL9Of8jXDQdyr6npL7keIa+Vlo7xPcwj9uv8OecAPqtUf/8WFAz71Acke4zUKVOmREREU1NT59sREUeOHOl2CfBLL70Ub775ZmzatCk2bdoUEe/HbHt7e1RUVMR//ud/xtSpUz/THQEAAGDw6zFSZ8yYEaNGjYp9+/bFggULIiLi8OHD0dDQEJWVlV3WXnrppfGb3/ymy7EtW7bEH//4x9i0aVNMnDixD0cHAABgsOkxUouLi2Px4sWxcePGGDduXIwfPz42bNgQVVVVUV5eHplMJk6dOhVjx46NkpKSbpf5jh49+pzHAQAA4ON69cxGq1ativnz58ftt98eS5cujalTp8bWrVsjImL//v1RXV0d+/fv79dBAQAAGPx6fCQ1IqKoqCjWrVsX69at6/axuXPnxqFDhz7xc//t3/7ts08HAADAkHJ+rxEDAAAAfUikAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJ6FWktrW1xebNm6O6ujoqKiqipqYmjh49+onrn3766ViwYEGUl5fHV77ylfjJT34SbW1tfTY0AAAAg1OvInXbtm2xZ8+eqK2tjZ07d0ZjY2OsXLnynGufffbZWLt2bdxwww3x61//OtasWRPbt2+Phx56qE8HBwAAYPDpMVIzmUzs2LEjVq9eHVdccUXMnDkztmzZEvX19VFfX99t/eOPPx7z5s2Lm266KS688ML46le/Gv/0T/8UTzzxRL/cAQAAAAaPop4WHDx4MM6cORNVVVWdx6ZNmxZlZWVRV1cXc+bM6bL+1ltvjZEjR3Y5VlBQEO+++24fjQwAAMBg1WOkNjY2RkTEpEmTuhyfOHFi58c+6tJLL+3y/unTp2PXrl1x5ZVXns+cAAAADAE9Rmpzc3MUFBTE8OHDuxwvLi6OlpaWHj93xYoV0dLSEmvWrMl6uPHjR2f9OQCpKy0dk+sR8p7vYX6xXwC5ka+/f3uM1JKSkmhvb4/W1tYoKvpweSaTiREjRnzi5x0/fjxWrFgRb7zxRjz66KNRVlaW9XDHjp2O9vaOrD9vIOTrhgO519T0l1yPkNdKS8f4HuYR+3X+nHMAn1Wqv38LCoZ96gOSPT5x0pQpUyIioqmpqcvxI0eOdLsE+AOHDx+Ob3zjG3H48OHYuXNnt0uAAQAA4Fx6jNQZM2bEqFGjYt++fZ3HDh8+HA0NDVFZWdlt/bFjx2Lp0qXR3t4eu3btihkzZvTtxAAAAAxaPV7uW1xcHIsXL46NGzfGuHHjYvz48bFhw4aoqqqK8vLyyGQycerUqRg7dmwUFxfHhg0b4sSJE/Gzn/0sSkpKOh+BHTZsWEyYMKHf7xAAAAD5q8dIjYhYtWpVtLa2xu233x6tra1x5ZVXxl133RUREfv374+lS5fGjh07Yvbs2fHb3/422tvb44YbbujyNQoLC+PAgQN9fw8AAAAYNHoVqUVFRbFu3bpYt25dt4/NnTs3Dh061Pn+q6++2nfTAQAAMKT0+DepAAAAMFBEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAkQ6QCAACQDJEKAABAMkQqAAAAyRCpAAAAJEOkAgAAkAyRCgAAQDJEKgAAAMkQqQAAACRDpAIAAJAMkQoAAEAyRCoAAADJEKkAAAAko1eR2tbWFps3b47q6uqoqKiImpqaOHr06Ceuf/nll2PRokUxe/bsmDdvXuzdu7ev5gUAAGAQ61Wkbtu2Lfbs2RO1tbWxc+fOaGxsjJUrV55z7fHjx2PZsmUxc+bMeOKJJ2LJkiWxfv36eO655/p0cAAAAAafop4WZDKZ2LFjR3z3u9+NK664IiIitmzZEtdee23U19fHnDlzuqz/1a9+FaNHj47169dHQUFBTJ8+PQ4cOBCPPvpoVFdX98+9AAAAYFDo8ZHUgwcPxpkzZ6Kqqqrz2LRp06KsrCzq6uq6ra+rq4vKysooKPjwS1dVVUV9fX10dHT00dgAAAAMRj0+ktrY2BgREZMmTepyfOLEiZ0f+/j6Sy65pNva5ubmOHHiRFxwwQW9Hq6gYFiv1+bCRZNzPUE/+ZuLcj1Bv5hWPDg3rOCiC3M9Qr/5/6YW5nqEfpH677Z84HuYX+zX+XPOkV8G6zlHxOA973DOMbB6mqvHSG1ubo6CgoIYPnx4l+PFxcXR0tLSbf3Zs2ejuLi429qI9y8dzsa4caOyWj/Q/t8vcz1BP1nzVq4n6Bcvlu/J9Qj9ovStA7keod/882+m5nqEfjF+/Ohcj5D3fA/zi/06f8458stgPeeIGLznHc450tLj5b4lJSXR3t4era2tXY5nMpkYMWLEOdd/PEY/eP9c6wEAAOADPUbqlClTIiKiqampy/EjR450uwQ4ImLy5MnnXDty5MgYM2bM+cwKAADAINdjpM6YMSNGjRoV+/bt6zx2+PDhaGhoiMrKym7rL7vssqirq+vyJEkvvvhizJkzp8uTKQEAAMDH9ViNxcXFsXjx4ti4cWP87ne/iz/84Q+xevXqqKqqivLy8shkMtHU1NR5Se/ChQvj+PHjcffdd8ebb74Zjz32WDz11FOxbNmyfr8zAAAA5LdhHb14XZjW1tbYtGlT7NmzJ1pbW+PKK6+Mu+66Ky644IJ48cUXY+nSpbFjx46YO3duRET8z//8T/zrv/5rHDp0KKZOnRo1NTXx93//9/1+ZwAAAMhvvYpUAAAAGAj+SBQAAIBkiFQAAACSIVIBAABIhkjNsba2tti8eXNUV1dHRUVF1NTUxNGjRz9x/csvvxyLFi2K2bNnx7x582Lv3r0DNywRkf2ePf3007FgwYIoLy+Pr3zlK/GTn/wk2traBnDioS3b/fqo5cuXx5IlS/p5Qj4q2/1qbGyMmpqaqKioiMsvvzzuueeeaG5uHsCJh7Zs9+uFF16IhQsXRnl5eVx33XWxffv28NQYuXHXXXfF+vXrP3WNc4609GbPnHOkozf79VHOOboSqTm2bdu22LNnT9TW1sbOnTujsbExVq5cec61x48fj2XLlsXMmTPjiSeeiCVLlsT69evjueeeG+Cph7Zs9uzZZ5+NtWvXxg033BC//vWvY82aNbF9+/Z46KGHBnjqoSub/fqoxx9/PJ555pn+H5AustmvTCYTN998c5w8eTJ27doV9913XzzzzDNx7733DvDUQ1c2+/X222/HLbfcEldffXU8+eSTsXbt2njggQfiF7/4xQBPPbR1dHTE1q1b45e//OWnrnPOkY7e7plzjjT0dr8+yjnHOXSQMy0tLR0VFRUd//Ef/9F57J133un427/9247//u//7rb+oYce6rjmmms62traOo+tW7eu4+abbx6Qecl+z2655ZaO2267rcux+++/v+Oaa67p71HpyH6/PvDWW291VFVVddx4440dN91000CMSkf2+7V79+6Oyy67rOPkyZNdjl1//fUDMu9Ql+1+PfbYYx1VVVVdjtXU1HQsX76832flff/7v//bcdNNN3XMnTu34+qrr+74zne+84lrnXOkIZs9c86Re9ns1wecc5ybR1Jz6ODBg3HmzJmoqqrqPDZt2rQoKyuLurq6buvr6uqisrIyCgo+3Laqqqqor693udQAyXbPbr311vjWt77V5VhBQUG8++67/T4r2e9XxPuXL95xxx2xbNmymD59+kCNSmS/X88991x86UtfirFjx3Yeu/7662P37t0DMu9Ql+1+XXDBBXHy5Ml46qmnor29PV577bWoq6uLWbNmDeTYQ1p9fX1MmTIlnnzyyZg2bdqnrnXOkYZs9sw5R+5ls18Rzjk+jUjNocbGxoiImDRpUpfjEydO7PzYx9efa21zc3OcOHGi/walU7Z7dumll8bFF1/c+f7p06dj165dceWVV/bvoERE9vsVEfHwww9HRMQ3v/nN/h2ObrLdr7feeivKysriRz/6UVxzzTVx7bXXRm1tbbS0tAzIvENdtvs1b968WLhwYaxduzZmzZoV8+fPj8rKylixYsWAzEvEggULYuPGjVFaWtrjWuccachmz5xz5F42+xXhnOPTiNQcam5ujoKCghg+fHiX48XFxec8yTp79mwUFxd3Wxvx/t9m0f+y3bOPf+6KFSuipaUl1qxZ059j8n+y3a9XXnklfvrTn0ZtbW2XRw8YGNnu1+nTp2P37t3xzjvvxNatW+POO++Mp59+Or73ve8N1MhDWrb79e6770ZDQ0MsW7Ysdu/eHbW1tfH888/H/fffP1AjkwXnHPnNOUf6nHN8uqJcDzCUlZSURHt7e7S2tkZR0YdbkclkYsSIEedc//H/Y/jg/XOtp+9lu2cfOH78eKxYsSLeeOONePTRR6OsrGwgxh3ystmvlpaW+Pa3vx2rVq2Kiy66aKBHJbL/+SoqKoqxY8fGxo0bo7CwML7whS9Ea2tr3HbbbXHnnXfGuHHjBnL8ISfb/dq0aVMUFhbG2rVrIyLikksuidbW1rjnnntiyZIl9isxzjnyl3OO9Dnn6Jlsz6EpU6ZERERTU1OX40eOHOl2iU1ExOTJk8+5duTIkTFmzJj+G5RO2e5ZRMThw4fjG9/4Rhw+fDh27twZl156ab/Pyfuy2a+XXnop3nzzzdi0aVNUVFRERUVF7N27N+rq6qKioiL++Mc/DtjcQ1W2P1+TJk2K6dOnR2FhYeexDy51a2ho6MdJich+v1566aVuf386e/bseO+99+JPf/pT/w3KZ+KcIz8558gPzjl6JlJzaMaMGTFq1KjYt29f57HDhw9HQ0NDVFZWdlt/2WWXRV1dXZcnLHjxxRdjzpw5LhMYINnu2bFjx2Lp0qXR3t4eu3btihkzZgzkuENeNvt16aWXxm9+85vYu3dv5z/XXXddzJo1K/bu3RsTJ04c6PGHnGx/vr74xS/Gq6++Gu+9917nsddeey0KCws9cjAAst2vyZMnx6FDh7oce/3116OgoCAuvPDCfp+X7DjnyD/OOfKHc46eudw3h4qLi2Px4sWxcePGGDduXIwfPz42bNgQVVVVUV5eHplMJk6dOhVjx46N4uLiWLhwYTzyyCNx9913xz/+4z/G888/H0899VRs374913dlyMh2zzZs2BAnTpyIn/3sZ1FSUtL5X6WHDRsWEyZMyPG9Gfyy2a+SkpJul9yMHj36nMfpH9n+fC1atCgee+yxuOOOO+Jf/uVf4s9//nPce++9sWDBApeODoBs92vp0qWxfPnyePDBB2P+/PnxxhtvxA9/+MNYvHhxjB49Otd3Z8hzzpF/nHPkF+cc2fGfwnJs1apVMX/+/Lj99ttj6dKlMXXq1Ni6dWtEROzfvz+qq6tj//79ERExYcKEeOSRR+LAgQPxta99LXbu3Bm1tbVx+eWX5/IuDDm93bOzZ8/Gb3/72/jrX/8aN9xwQ1RXV3f+8+UvfznH92LoyOZnjNzL9nfiz3/+8zh16lR8/etfjzVr1sS8efNiw4YNubwLQ0o2+3XVVVfF/fffH//1X/8V//AP/xA/+MEP4sYbb4x169bl8i7wf5xz5B/nHPnFOUd2hnV4sSsAAAAS4ZFUAAAAkiFSAQAASIZIBQAAIBkiFQAAgGSIVAAAAJIhUgEAAEiGSAUAACAZIhUAAIBkiFQAAACS8f8DdA/cGl3DvUcAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "barplot_multiple_columns(groups=['training', 'validation'],\n",
    "                         elements_group=df_test_metric['model'].unique(), data=metrics, yerr=y_errs,\n",
    "                         title='Test metrics')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_svm = calculate_statistics_sklearn(svm_res, 'svc')\n",
    "df_test_metric = summary_statistics_model(df_test_metric, res_svm, 'svc')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                      model     f1_mu    acc_mu   loss_mu     f1_ci    acc_ci  \\\n0                       mlp  0.861018  0.861018  0.861018  0.009781  0.009781   \n1  random_forest_classifier  0.609757  0.607742  0.392258  0.006530  0.007129   \n2  decision_tree_classifier  0.640291  0.639918  0.360082  0.004217  0.004052   \n3               gaussian_nb  0.452680  0.451814  0.548186  0.010686  0.010409   \n4                       qda  0.521724  0.535026  0.464974  0.007964  0.008279   \n5                       svc  0.828621  0.829239  0.170761  0.004228  0.004051   \n\n    loss_ci  \n0  0.009781  \n1  0.007129  \n2  0.004052  \n3  0.010409  \n4  0.008279  \n5  0.004051  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>f1_mu</th>\n      <th>acc_mu</th>\n      <th>loss_mu</th>\n      <th>f1_ci</th>\n      <th>acc_ci</th>\n      <th>loss_ci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mlp</td>\n      <td>0.861018</td>\n      <td>0.861018</td>\n      <td>0.861018</td>\n      <td>0.009781</td>\n      <td>0.009781</td>\n      <td>0.009781</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>random_forest_classifier</td>\n      <td>0.609757</td>\n      <td>0.607742</td>\n      <td>0.392258</td>\n      <td>0.006530</td>\n      <td>0.007129</td>\n      <td>0.007129</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>decision_tree_classifier</td>\n      <td>0.640291</td>\n      <td>0.639918</td>\n      <td>0.360082</td>\n      <td>0.004217</td>\n      <td>0.004052</td>\n      <td>0.004052</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gaussian_nb</td>\n      <td>0.452680</td>\n      <td>0.451814</td>\n      <td>0.548186</td>\n      <td>0.010686</td>\n      <td>0.010409</td>\n      <td>0.010409</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>qda</td>\n      <td>0.521724</td>\n      <td>0.535026</td>\n      <td>0.464974</td>\n      <td>0.007964</td>\n      <td>0.008279</td>\n      <td>0.008279</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>svc</td>\n      <td>0.828621</td>\n      <td>0.829239</td>\n      <td>0.170761</td>\n      <td>0.004228</td>\n      <td>0.004051</td>\n      <td>0.004051</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: export DataFrame\n",
    "df_test_metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.86101756, 0.60975699, 0.64029135, 0.45268028, 0.52172352,\n",
      "       0.82862069]), array([0.86101756, 0.60774242, 0.63991837, 0.4518136 , 0.53502594,\n",
      "       0.82923866]), array([0.86101756, 0.39225758, 0.36008163, 0.5481864 , 0.46497406,\n",
      "       0.17076134])]\n",
      "[array([0.00978116, 0.00652968, 0.00421678, 0.01068605, 0.0079638 ,\n",
      "       0.00422756]), array([0.00978116, 0.00712947, 0.00405215, 0.01040924, 0.00827923,\n",
      "       0.00405127]), array([0.00978116, 0.00712947, 0.00405215, 0.01040924, 0.00827923,\n",
      "       0.00405127])]\n"
     ]
    }
   ],
   "source": [
    "from src.visualization.visualize import barplot_multiple_columns\n",
    "import numpy as np\n",
    "\n",
    "# TODO: change function and params name? Return new list or use reference (it works)?\n",
    "def add_value_array(old_list: List, df_test: pd.DataFrame, col_name: str) -> None:\n",
    "    tmp = []\n",
    "    for model_name in df_test['model'].unique():\n",
    "            metric_value = df_test[df_test['model'] == model_name][col_name].values[0]\n",
    "            tmp.append(metric_value)\n",
    "    old_list.append(np.array(tmp))\n",
    "\n",
    "metrics = []\n",
    "add_value_array(metrics, df_test_metric, 'f1_mu')\n",
    "add_value_array(metrics, df_test_metric, 'acc_mu')\n",
    "add_value_array(metrics, df_test_metric, 'loss_mu')\n",
    "print(metrics)\n",
    "\n",
    "\n",
    "y_errs = []\n",
    "add_value_array(y_errs, df_test_metric, 'f1_ci')\n",
    "add_value_array(y_errs, df_test_metric, 'acc_ci')\n",
    "add_value_array(y_errs, df_test_metric, 'loss_ci')\n",
    "print(y_errs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "barplot_multiple_columns(groups=df_test_metric['model'].unique(), elements_group=['f1', 'acc', 'loss'], data=metrics, yerr=y_errs, title='Test metrics')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}