{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Processed data storage"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we are going to merge all the part of the dataset together. In particular, we will use the dataset that we made in the previous notebook that are:\n",
    "- _movies_\n",
    "- _tags_\n",
    "- _ratings_\n",
    "- _tmdb_\n",
    "- _genome_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils.const import DATA_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Useful path to data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join(os.getcwd(), '..')\n",
    "INTERIM_DIR = os.path.join(ROOT_DIR, DATA_DIR, 'interim')\n",
    "PROCESSED_DIR = os.path.join(ROOT_DIR, DATA_DIR, 'processed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import all interim data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the pre-process that we made in the previous notebook, we decided to save the intermediate results in the interim folder in a parquet format. We are now going to read these preprocessed dataset in order to build the final one."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "movies = pd.read_parquet(\n",
    "    os.path.join(INTERIM_DIR, 'movies.parquet')\n",
    ")\n",
    "\n",
    "tags = pd.read_parquet(\n",
    "    os.path.join(INTERIM_DIR, 'tags.parquet')\n",
    ")\n",
    "\n",
    "ratings = pd.read_parquet(\n",
    "    os.path.join(INTERIM_DIR, 'ratings.parquet')\n",
    ")\n",
    "\n",
    "tmdb = pd.read_parquet(\n",
    "    os.path.join(INTERIM_DIR, 'tmdb.parquet')\n",
    ")\n",
    "\n",
    "genome = pd.read_parquet(\n",
    "    os.path.join(INTERIM_DIR, 'genome.parquet')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merging all the datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thanks to our previous elaboration on these datasets, we are now ready to merge them together, just using the pandas' merge function. We use on all the merge function the _inner_ method, because we want to keep only the data that are common to all the dataset except for the tags. We decided to keep also the films that doesn't have any tag and fill these films with 0 as _tag_count_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "final = (movies\n",
    "         .merge(ratings, on='movieId', how='inner')\n",
    "         .merge(tags, on='movieId', how='left')\n",
    "         .merge(tmdb, on='movieId', how='inner')\n",
    "         .merge(genome, on='movieId', how='inner'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fill tag_count with 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "final = (final\n",
    "         .fillna({'tag_count': 0})\n",
    "         .drop(columns='movieId'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies dimensionality: (13147, 1153)\n"
     ]
    }
   ],
   "source": [
    "print(f'Movies dimensionality: {final.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}