{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imbalance evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours, RandomUnderSampler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from src.utils.const import DATA_DIR, SEED\n",
    "from src.utils.util_models import fix_random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Useful path to data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join(os.getcwd(), '..')\n",
    "PROCESSED_DIR = os.path.join(ROOT_DIR, DATA_DIR, 'processed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Repeatability"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "fix_random(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start to work"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "final = pd.read_parquet(os.path.join(PROCESSED_DIR, 'final.parquet'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add rating_discrete feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13147 entries, 0 to 13146\n",
      "Columns: 1153 entries, year to rating_discrete\n",
      "dtypes: float32(1130), float64(1), int32(22)\n",
      "memory usage: 58.0 MB\n"
     ]
    }
   ],
   "source": [
    "bins = 10\n",
    "final = (final\n",
    "         .assign(rating_discrete=pd.cut(final.loc[:, 'rating_mean'], bins=bins, labels=False))\n",
    "         .astype({'rating_discrete': 'int32'})\n",
    "         .drop(columns=['rating_mean']))\n",
    "final.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Separate train/test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data = final.loc[:, final.columns != 'rating_discrete']\n",
    "target = final['rating_discrete']\n",
    "train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.2,\n",
    "                                                                    stratify=final['rating_discrete'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def try_sample(model, train_data_inside, train_target_inside) -> None:\n",
    "    # Define evaluation procedure (here we use Repeated Stratified K-Fold CV)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    # Evaluate model\n",
    "    scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "    scores = cross_validate(model, train_data_inside, train_target_inside, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "    # summarize performance\n",
    "    print('Mean Accuracy: %.4f' % np.mean(scores['test_accuracy']))\n",
    "    print('Mean Precision: %.4f' % np.mean(scores['test_precision_macro']))\n",
    "    print('Mean Recall: %.4f' % np.mean(scores['test_recall_macro']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### class_weights = 'balanced'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7546\n",
      "Mean Precision: 0.6551\n",
      "Mean Recall: 0.5271\n"
     ]
    }
   ],
   "source": [
    "model_balanced = RandomForestClassifier(criterion='entropy', class_weight='balanced')\n",
    "try_sample(model_balanced, train_data, train_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### class_weights = 'balanced_subsample'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7565\n",
      "Mean Precision: 0.6888\n",
      "Mean Recall: 0.5504\n"
     ]
    }
   ],
   "source": [
    "model_balanced_subsample = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample')\n",
    "try_sample(model_balanced_subsample, train_data, train_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### class_weights = dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7547\n",
      "Mean Precision: 0.6517\n",
      "Mean Recall: 0.5211\n"
     ]
    }
   ],
   "source": [
    "class_weight = compute_class_weight('balanced', classes=np.unique(target), y=target)\n",
    "class_weight_dict = dict(enumerate(class_weight))\n",
    "\n",
    "model_dict = RandomForestClassifier(criterion='entropy', class_weight=class_weight_dict)\n",
    "try_sample(model_dict, train_data, train_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transformations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "features = [\n",
    "    'year',\n",
    "    'title_length',\n",
    "    'runtime',\n",
    "    'rating_count',\n",
    "    'tag_count'\n",
    "]\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers=[\n",
    "        ('minmax', MinMaxScaler(), features)\n",
    "    ])\n",
    "\n",
    "norm = Normalizer(norm='l2')\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', scaler),\n",
    "    ('norm', norm)\n",
    "])\n",
    "\n",
    "pipe.fit(train_data)\n",
    "train_data_proc = pipe.transform(train_data)\n",
    "test_data_proc = pipe.transform(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SMOTE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9374\n",
      "Mean Precision: 0.9368\n",
      "Mean Recall: 0.9374\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTE(k_neighbors=4)\n",
    "train_data_smt, train_target_smt = smt.fit_resample(train_data, train_target)\n",
    "model_smt = RandomForestClassifier(criterion='entropy')\n",
    "try_sample(model_smt, train_data_smt, train_target_smt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9386\n",
      "Mean Precision: 0.9383\n",
      "Mean Recall: 0.9386\n"
     ]
    }
   ],
   "source": [
    "train_data_smt_proc, train_target_smt_proc = smt.fit_resample(train_data_proc, train_target)\n",
    "model_smt_proc = RandomForestClassifier(criterion='entropy')\n",
    "try_sample(model_smt_proc, train_data_smt_proc, train_target_smt_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SMOTETomek"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.00300000e+03 3.60000000e+01 0.00000000e+00 ... 1.70000009e-02\n",
      "  7.37499967e-02 1.89999994e-02]\n",
      " [1.99300000e+03 1.70000000e+01 1.00000000e+00 ... 5.12499996e-02\n",
      "  1.27250001e-01 1.89999994e-02]\n",
      " [2.01600000e+03 3.50000000e+01 1.00000000e+00 ... 1.02500003e-02\n",
      "  1.36999995e-01 1.89999994e-02]\n",
      " ...\n",
      " [1.99781982e+03 2.80000000e+01 0.00000000e+00 ... 2.46404380e-01\n",
      "  9.90540758e-02 2.61553973e-02]\n",
      " [2.00494226e+03 5.00000000e+01 0.00000000e+00 ... 3.05222511e-01\n",
      "  7.68955573e-02 2.03819443e-02]\n",
      " [1.96693555e+03 2.30000000e+01 0.00000000e+00 ... 5.01719862e-02\n",
      "  7.62721226e-02 2.08621714e-02]]\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(array([    1,     3,     4, ..., 32197, 32198, 32199]), slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\analytics\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\analytics\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\analytics\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '(array([    1,     3,     4, ..., 32197, 32198, 32199]), slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_data_smt_tom\u001B[38;5;241m.\u001B[39mto_numpy())\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_idx, val_idx \u001B[38;5;129;01min\u001B[39;00m cv\u001B[38;5;241m.\u001B[39msplit(train_data_smt_tom\u001B[38;5;241m.\u001B[39mto_numpy(), y\u001B[38;5;241m=\u001B[39mtrain_target_smt_tom\u001B[38;5;241m.\u001B[39mto_numpy()):\n\u001B[1;32m---> 10\u001B[0m     X_train, X_val \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_data_smt_tom\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m, train_data_smt_tom[val_idx, :]\n\u001B[0;32m     11\u001B[0m     y_train, y_val \u001B[38;5;241m=\u001B[39m train_target[train_idx], train_target[val_idx]\n\u001B[0;32m     13\u001B[0m     model_smt_tom\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\analytics\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\analytics\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3623\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3624\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3625\u001B[0m         \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3626\u001B[0m         \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3627\u001B[0m         \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m-> 3628\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3629\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m   3631\u001B[0m \u001B[38;5;66;03m# GH#42269\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\analytics\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   5633\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m   5634\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[0;32m   5635\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[0;32m   5636\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[1;32m-> 5637\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m: (array([    1,     3,     4, ..., 32197, 32198, 32199]), slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "smt_tom = SMOTETomek(smote=SMOTE(k_neighbors=4), tomek=TomekLinks(sampling_strategy='majority'))\n",
    "train_data_smt_tom, train_target_smt_tom = smt_tom.fit_resample(train_data, train_target)\n",
    "model_smt_tom = DecisionTreeClassifier(criterion='entropy', max_depth=15)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "\n",
    "losses = []\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in cv.split(train_data_smt_tom.to_numpy(), y=train_target_smt_tom.to_numpy()):\n",
    "    X_train, X_val = train_data_smt_tom[train_idx, :], train_data_smt_tom[val_idx, :]\n",
    "    y_train, y_val = train_target[train_idx], train_target[val_idx]\n",
    "\n",
    "    model_smt_tom.fit(X_train, y_train)\n",
    "\n",
    "    predicted_target = model_smt_tom.predict(X_val)\n",
    "    loss = zero_one_loss(y_val, predicted_target)\n",
    "    score = model_smt_tom.score(X_val, y_val)\n",
    "\n",
    "    losses.append(loss)\n",
    "    scores.append(score)\n",
    "\n",
    "    print(f'Loss: {loss:.3f}')\n",
    "    print(f'Accuracy: {score:.3f}')\n",
    "\n",
    "print(f'Mean losses: {np.mean(losses)}')\n",
    "print(f'Mean scores: {np.mean(scores)}')\n",
    "\n",
    "predicted_target = model_smt_tom.predict(test_data_proc)\n",
    "loss = zero_one_loss(test_target, predicted_target)\n",
    "score = model_smt_tom.score(test_data_proc, test_target)\n",
    "print(f'Loss TEST: {loss:.3f}')\n",
    "print(f'Accuracy TEST: {score:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9397\n",
      "Mean Precision: 0.9386\n",
      "Mean Recall: 0.9389\n"
     ]
    }
   ],
   "source": [
    "train_data_smt_tom_proc, train_target_smt_tom_proc = smt_tom.fit_resample(train_data_proc, train_target)\n",
    "model_smt_tom_proc = RandomForestClassifier(criterion='entropy')\n",
    "try_sample(model_smt_tom_proc, train_data_smt_tom_proc, train_target_smt_tom_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SMOTEENN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smt_enn = SMOTEENN(smote=SMOTE(k_neighbors=4), enn=EditedNearestNeighbours(n_neighbors=4))\n",
    "train_data_smt_enn, train_target_smt_enn = smt_enn.fit_resample(train_data, train_target)\n",
    "model_smt_enn = RandomForestClassifier(criterion='entropy')\n",
    "try_sample(model_smt_enn, train_data_smt_enn, train_target_smt_enn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smt_enn = SMOTEENN(smote=SMOTE(k_neighbors=4), enn=EditedNearestNeighbours(n_neighbors=4))\n",
    "train_data_smt_enn_proc, train_target_smt_enn_proc = smt_enn.fit_resample(train_data_proc, train_target)\n",
    "model_smt_enn_proc = RandomForestClassifier(criterion='entropy')\n",
    "try_sample(model_smt_enn_proc, train_data_smt_enn_proc, train_target_smt_enn_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RandomOverSampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rnd_over = RandomOverSampler()\n",
    "train_data_rnd_over, train_target_rnd_over = rnd_over.fit_resample(train_data, train_target)\n",
    "model_rnd_over = RandomForestClassifier(criterion='entropy')\n",
    "try_sample(model_rnd_over, train_data_rnd_over, train_target_rnd_over)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rnd_over = RandomOverSampler()\n",
    "train_data_rnd_over_proc, train_target_rnd_over_proc = rnd_over.fit_resample(train_data_proc, train_target)\n",
    "model_rnd_over_proc = RandomForestClassifier(criterion='entropy')\n",
    "try_sample(model_rnd_over_proc, train_data_rnd_over_proc, train_target_rnd_over_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SMOTE with threshold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.8006\n",
      "Mean Precision: 0.8777\n",
      "Mean Recall: 0.8378\n"
     ]
    }
   ],
   "source": [
    "bins_count = train_target.value_counts()\n",
    "for i in range(len(bins_count)):\n",
    "    if bins_count[i] <= 500:\n",
    "        bins_count[i] = 500\n",
    "\n",
    "bin_sizes = bins_count.to_dict()\n",
    "\n",
    "smt_new = SMOTE(k_neighbors=4, sampling_strategy=bin_sizes)\n",
    "train_data_smt_new, train_target_smt_new = smt_new.fit_resample(train_data_proc, train_target)\n",
    "model_smt_new = RandomForestClassifier(criterion='entropy')\n",
    "try_sample(model_smt_new, train_data_smt_new, train_target_smt_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7997\n",
      "Mean Precision: 0.8808\n",
      "Mean Recall: 0.8329\n"
     ]
    }
   ],
   "source": [
    "smt_new = SMOTE(k_neighbors=4, sampling_strategy=bin_sizes)\n",
    "train_data_smt_new_proc, train_target_smt_new_proc = smt_new.fit_resample(train_data_proc, train_target)\n",
    "model_smt_new_bagging = BaggingClassifier(base_estimator=RandomForestClassifier(criterion='entropy'))\n",
    "try_sample(model_smt_new_bagging, train_data_smt_new_proc, train_target_smt_new_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}